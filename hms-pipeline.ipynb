{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Training Pipeline\n","\n","All dataloading and training in one place!"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-14T05:18:43.921801Z","iopub.status.busy":"2024-04-14T05:18:43.921227Z","iopub.status.idle":"2024-04-14T05:18:52.582521Z","shell.execute_reply":"2024-04-14T05:18:52.581567Z","shell.execute_reply.started":"2024-04-14T05:18:43.921765Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from sklearn.model_selection import KFold, GroupKFold, train_test_split\n","from datetime import datetime\n","from tqdm.notebook import tqdm\n","import albumentations as A\n","import matplotlib.pyplot as plt\n","import os\n","from typing import List, Tuple, Union\n","import pickle\n","from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n","from torcheval.metrics import MulticlassAccuracy\n","from torcheval.metrics.functional import multiclass_f1_score\n","\n","#Local packages\n","from src import CNNDetector\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\"\"\"\n","Configure\n","\n","Change the paths of the data directory to the location of your HMS Dataset.\n","The sub directories of TRAIN/TEST_EEG, TRAIN/TEST_SPEC should remain the same\n","\n","\"\"\"\n","\n","#Kaggle\n","# DATA_ROOT = \"/kaggle/input/hms-harmful-brain-activity-classification/\"\n","# TRAIN_EEG = \"train_eegs\"\n","# TRAIN_SPEC = \"train_spectrograms\"\n","# TEST_EEG = \"test_eegs\"\n","# TEST_SPEC = \"test_spectrograms\"\n","\n","#Local\n","DATA_ROOT = \"/home/benluo/HBAC/data/hbac\"\n","TRAIN_EEG = \"train_eegs\"\n","TRAIN_SPEC = \"train_spectrograms\"\n","TEST_EEG = \"test_eegs\"\n","TEST_SPEC = \"test_spectrograms\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:18:52.584370Z","iopub.status.busy":"2024-04-14T05:18:52.583950Z","iopub.status.idle":"2024-04-14T05:18:52.616226Z","shell.execute_reply":"2024-04-14T05:18:52.615329Z","shell.execute_reply.started":"2024-04-14T05:18:52.584344Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#Get reduced train list as the entire dataset is heavy on RAM, \n","\n","train_list = pd.read_csv(os.path.join(DATA_ROOT, \"train.csv\"))\n","\n","reduced_len = train_list.shape[0]//2 #32 GB of RAM during training\n","# reduced_len = train_list.shape[0]//4 #Less RAM but less data\n","\n","train_list_reduced = train_list.iloc[:reduced_len,:]\n","\n","train_list_reduced.to_csv(os.path.join(DATA_ROOT, \"train_reduced.csv\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Generate Data\n","\n","Since test data does not come with labels, for local training and testing, we will only use the data from `train.csv`\n","\n","The Dataset follows a train-val-test split.\n","\n","The train and test datasets are split first by `test_size`.\n","\n","The train and validation datasets are split by Group K-Folds into `val_folds` uniform groups. One group will be chosen randomly for validation while the rest will be used for training every epoch."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def generate_data(val_folds:int = 5,\n","                  test_size:float = 0.1,\n","                  saved_spec:str = \"all_spec.pkl\",\n","                  saved_eeg:str = \"all_eeg.pkl\"):\n","\n","    #Use reduced csv file\n","    train_list = pd.read_csv(os.path.join(DATA_ROOT, \"train_reduced.csv\"))\n","\n","    print(\"All data\", train_list.shape)\n","    display(train_list.head())\n","\n","    label_cols = train_list.columns[-6:]\n","\n","    #Create new df to be formated for training and testing\n","    train_df = train_list[['spectrogram_id','eeg_id','patient_id','spectrogram_label_offset_seconds','eeg_label_offset_seconds']]\n","\n","    #Normalise labels into probabilities\n","    aux = train_list[label_cols].copy()\n","    \n","    for label in label_cols:\n","        train_df[label] = aux[label].values\n","        \n","    y_data = train_df[label_cols].values\n","    y_data = y_data / y_data.sum(axis=1,keepdims=True)\n","    train_df[label_cols] = y_data\n","\n","    #Target label/class\n","    aux = train_list['expert_consensus'].copy()\n","    train_df['target'] = aux\n","    train_df = train_df.reset_index()\n","\n","    #Sort df by patient id so testing and training data will be less similar\n","    train_df = train_df.sort_values(\"patient_id\")\n","\n","    test_df = train_df.iloc[int((1-test_size)*train_df.shape[0]):]\n","\n","    train_df = train_df.iloc[:int((1-test_size)*train_df.shape[0])]\n","\n","    train_df = train_df.reset_index()\n","    test_df = test_df.reset_index()\n","\n","    print(\"Training data\")\n","    display(train_df.head())\n","\n","    print(\"Testing data\")\n","    display(test_df.head())\n","\n","\n","    gkf = GroupKFold(n_splits=val_folds)\n","\n","    #KFold grouped by patient id\n","    for fold, (train_index, val_index) in enumerate(gkf.split(train_df, train_df.target, train_df.patient_id)):\n","        train_df.loc[val_index, \"fold\"] = int(fold)\n","    \n","    all_eeg = {}\n","    \n","    all_spec = {}\n","\n","    #Try loading eeg and spec data if they have been generated previously\n","    #If not, read eeg and spec data from train_list and save the collection in data folder\n","    #Data is saved as float16 due to space constraints\n","    try:\n","\n","        with open(os.path.join(DATA_ROOT,saved_spec), \"rb\") as handle:\n","            all_spec = pickle.load(handle)\n","\n","        with open(os.path.join(DATA_ROOT,saved_eeg), \"rb\") as handle:\n","            all_eeg = pickle.load(handle)\n","\n","    except:\n","    \n","        for idx, row in tqdm(train_list.iterrows()):\n","\n","            spec_id = row[\"spectrogram_id\"]\n","            eeg_id = row[\"eeg_id\"]\n","\n","            if spec_id not in all_spec:\n","\n","                spec = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_SPEC, str(spec_id)+\".parquet\"))\n","\n","                all_spec[spec_id] = spec.iloc[:,1:].values.astype(dtype=np.float32)\n","\n","            if eeg_id not in all_eeg:\n","\n","                eeg = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_EEG, str(eeg_id)+\".parquet\"))\n","\n","                all_eeg[eeg_id] = eeg.iloc[:,1:].values.astype(dtype=np.float32)\n","        \n","        with open(os.path.join(DATA_ROOT, saved_eeg), \"wb\") as handle:\n","            pickle.dump(all_eeg, handle)\n","        \n","        with open(os.path.join(DATA_ROOT, saved_spec), \"wb\") as handle:\n","            pickle.dump(all_spec, handle)\n","    \n","    return train_df, test_df, all_eeg, all_spec, label_cols"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All data (53400, 16)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>eeg_id</th>\n","      <th>eeg_sub_id</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>spectrogram_id</th>\n","      <th>spectrogram_sub_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>label_id</th>\n","      <th>patient_id</th>\n","      <th>expert_consensus</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1628180742</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>353733</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>127492639</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1628180742</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>353733</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>3887563113</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1628180742</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>353733</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>1142670488</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1628180742</td>\n","      <td>3</td>\n","      <td>18.0</td>\n","      <td>353733</td>\n","      <td>3</td>\n","      <td>18.0</td>\n","      <td>2718991173</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1628180742</td>\n","      <td>4</td>\n","      <td>24.0</td>\n","      <td>353733</td>\n","      <td>4</td>\n","      <td>24.0</td>\n","      <td>3080632009</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0      eeg_id  eeg_sub_id  eeg_label_offset_seconds  \\\n","0           0  1628180742           0                       0.0   \n","1           1  1628180742           1                       6.0   \n","2           2  1628180742           2                       8.0   \n","3           3  1628180742           3                      18.0   \n","4           4  1628180742           4                      24.0   \n","\n","   spectrogram_id  spectrogram_sub_id  spectrogram_label_offset_seconds  \\\n","0          353733                   0                               0.0   \n","1          353733                   1                               6.0   \n","2          353733                   2                               8.0   \n","3          353733                   3                              18.0   \n","4          353733                   4                              24.0   \n","\n","     label_id  patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  \\\n","0   127492639       42516          Seizure             3         0         0   \n","1  3887563113       42516          Seizure             3         0         0   \n","2  1142670488       42516          Seizure             3         0         0   \n","3  2718991173       42516          Seizure             3         0         0   \n","4  3080632009       42516          Seizure             3         0         0   \n","\n","   lrda_vote  grda_vote  other_vote  \n","0          0          0           0  \n","1          0          0           0  \n","2          0          0           0  \n","3          0          0           0  \n","4          0          0           0  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training data\n"]},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self[col] = igetitem(value, i)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>level_0</th>\n","      <th>index</th>\n","      <th>spectrogram_id</th>\n","      <th>eeg_id</th>\n","      <th>patient_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>41744</td>\n","      <td>41744</td>\n","      <td>802850878</td>\n","      <td>1873660287</td>\n","      <td>56</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>49045</td>\n","      <td>49045</td>\n","      <td>957002006</td>\n","      <td>165634434</td>\n","      <td>56</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41746</td>\n","      <td>41746</td>\n","      <td>802850878</td>\n","      <td>2057577408</td>\n","      <td>56</td>\n","      <td>290.0</td>\n","      <td>46.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>41745</td>\n","      <td>41745</td>\n","      <td>802850878</td>\n","      <td>2057577408</td>\n","      <td>56</td>\n","      <td>244.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>25278</td>\n","      <td>25278</td>\n","      <td>497667405</td>\n","      <td>374550767</td>\n","      <td>56</td>\n","      <td>694.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   level_0  index  spectrogram_id      eeg_id  patient_id  \\\n","0    41744  41744       802850878  1873660287          56   \n","1    49045  49045       957002006   165634434          56   \n","2    41746  41746       802850878  2057577408          56   \n","3    41745  41745       802850878  2057577408          56   \n","4    25278  25278       497667405   374550767          56   \n","\n","   spectrogram_label_offset_seconds  eeg_label_offset_seconds  seizure_vote  \\\n","0                               0.0                       0.0           0.0   \n","1                               0.0                       0.0           0.0   \n","2                             290.0                      46.0           0.0   \n","3                             244.0                       0.0           0.0   \n","4                             694.0                       0.0           0.0   \n","\n","   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote target  \n","0       0.0       0.0        0.0        0.0         1.0  Other  \n","1       0.0       0.0        0.0        0.0         1.0  Other  \n","2       0.0       0.0        0.0        0.0         1.0  Other  \n","3       0.0       0.0        0.0        0.0         1.0  Other  \n","4       0.0       0.0        0.0        0.0         1.0  Other  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Testing data\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>level_0</th>\n","      <th>index</th>\n","      <th>spectrogram_id</th>\n","      <th>eeg_id</th>\n","      <th>patient_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5410</td>\n","      <td>5410</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>122.0</td>\n","      <td>122.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5389</td>\n","      <td>5389</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>72.0</td>\n","      <td>72.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5384</td>\n","      <td>5384</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>60.0</td>\n","      <td>60.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5394</td>\n","      <td>5394</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>82.0</td>\n","      <td>82.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5385</td>\n","      <td>5385</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>62.0</td>\n","      <td>62.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   level_0  index  spectrogram_id      eeg_id  patient_id  \\\n","0     5410   5410        91996359  3686473557       57272   \n","1     5389   5389        91996359  3686473557       57272   \n","2     5384   5384        91996359  3686473557       57272   \n","3     5394   5394        91996359  3686473557       57272   \n","4     5385   5385        91996359  3686473557       57272   \n","\n","   spectrogram_label_offset_seconds  eeg_label_offset_seconds  seizure_vote  \\\n","0                             122.0                     122.0           0.0   \n","1                              72.0                      72.0           0.0   \n","2                              60.0                      60.0           0.0   \n","3                              82.0                      82.0           0.0   \n","4                              62.0                      62.0           0.0   \n","\n","   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote target  \n","0       0.0       0.0        1.0        0.0         0.0   LRDA  \n","1       0.0       0.0        1.0        0.0         0.0   LRDA  \n","2       0.0       0.0        1.0        0.0         0.0   LRDA  \n","3       0.0       0.0        1.0        0.0         0.0   LRDA  \n","4       0.0       0.0        1.0        0.0         0.0   LRDA  "]},"metadata":{},"output_type":"display_data"}],"source":["train_df, test_df, all_eeg, all_spec, label_cols = generate_data()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:37:19.304302Z","iopub.status.busy":"2024-04-14T05:37:19.303853Z","iopub.status.idle":"2024-04-14T05:37:19.335251Z","shell.execute_reply":"2024-04-14T05:37:19.334018Z","shell.execute_reply.started":"2024-04-14T05:37:19.304270Z"},"trusted":true},"outputs":[],"source":["class HMSDataset(Dataset):\n","\n","    def __init__(self,\n","                 df:pd.DataFrame = None,\n","                 aug: bool = False) -> None:\n","        \n","\n","        super(HMSDataset, self).__init__()\n","\n","        self.df = df\n","\n","        self.eeg_sample_freq = 200 # 200 Hz\n","        self.spec_sample_freq = 0.5 # 0.5 Hz\n","    \n","        \n","        #data augmentation\n","        self.aug = aug\n","        self.transforms = A.Compose([\n","            A.HorizontalFlip(p=0.5)\n","        ])\n","\n","    def format_data(self, eeg:np.array, spec:np.array) -> Tuple[torch.tensor]:\n","\n","        #Epsilon for numerical stability during division (prevent division by zero)\n","        eps = 1e-6\n","\n","        #Convert data from saved float16 to float32 during training and testing\n","        eeg = eeg.astype(dtype=np.float32)\n","        spec = spec.astype(dtype=np.float32)\n","\n","        #Normalising and getting rid of Nans\n","        eeg_mean = np.nanmean(eeg.flatten())\n","        eeg_std = np.nanstd(eeg.flatten())\n","        eeg = (eeg-eeg_mean)/(eeg_std+eps)\n","        eeg = np.nan_to_num(eeg, nan=0.0)\n","\n","        #Limiting range of spec data\n","        spec = np.clip(spec, np.exp(-4), np.exp(8))\n","        spec = np.log(spec)\n","        \n","        #Normalising and getting rid of Nans\n","        spec_mean = np.nanmean(spec.flatten())\n","        spec_std = np.nanstd(spec.flatten())\n","        spec = (spec-spec_mean)/(spec_std+eps)\n","        spec = np.nan_to_num(spec, nan=0.0)\n","        \n","        #If data augmentation\n","        if self.aug:\n","\n","            eeg = self.transforms(image=eeg)[\"image\"]\n","            spec = self.transforms(image=spec)[\"image\"]\n","\n","        #Convert to tensors\n","        eeg = torch.tensor(eeg.copy())\n","        spec = torch.tensor(spec.copy())\n","\n","        return eeg, spec\n","\n","\n","    def __getitem__(self, index) -> dict:\n","    \n","        row = self.df.iloc[index]\n","\n","        eeg_id = row[\"eeg_id\"]\n","        spec_id = row[\"spectrogram_id\"]\n","\n","        #EEG Sub-sampling\n","        start = int(row[\"eeg_label_offset_seconds\"]*self.eeg_sample_freq)\n","        end = int((row[\"eeg_label_offset_seconds\"]+50)*self.eeg_sample_freq)\n","        eeg = all_eeg[eeg_id][start:end]\n","        \n","        #Spectrogram Sub-sampling\n","        start = int(row[\"spectrogram_label_offset_seconds\"]*self.spec_sample_freq)\n","        end = int((row[\"spectrogram_label_offset_seconds\"]+600)*self.spec_sample_freq)\n","        spec = all_spec[spec_id][start:end].T\n","\n","        #Normalizing and getting rid of Nans\n","        eeg, spec = self.format_data(eeg, spec)\n","\n","        #Convert label to tensor\n","        label = torch.tensor(row[label_cols], dtype=torch.float32)\n","\n","        return eeg, spec, label\n","\n","\n","    def __len__(self):\n","\n","        return self.df.shape[0]\n","\n","    @staticmethod\n","    def collate_fn(batch):\n","\n","        eeg, spec, label = zip(*batch)\n","        \n","        if eeg is not None:\n","            eeg = torch.stack(eeg, dim=0).float().unsqueeze(1)\n","        \n","        if spec is not None:\n","            spec = torch.stack(spec, dim=0).float().unsqueeze(1).expand(-1,3,-1,-1)\n","\n","        if label is not None:            \n","            label = torch.stack(label, dim=0)\n","        \n","        return {\n","            \"eeg\": eeg,\n","            \"spec\": spec,\n","            \"label\": label\n","        }\n","    "]},{"cell_type":"markdown","metadata":{},"source":["### Model\n","\n","Load your model here, the current models are supported:\n","\n","1. CNN\n","    - ConvNext\n","    - EfficientNet b0\n","    - EfficientNet v2s\n","2. Vision Transformers\n","    - ViT tiny\n","    - Hiera tiny\n","3. Custom Architecture\n","    - dual stream"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NaiveCNN(\n","  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (avg_pool): AvgPool2d(kernel_size=5, stride=5, padding=0)\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (fc1): Linear(in_features=8512, out_features=512, bias=True)\n","  (drop1): Dropout(p=0.1, inplace=False)\n","  (fc2): Linear(in_features=512, out_features=6, bias=True)\n",")\n"]}],"source":["model_config = {\n","    \"model_name\": \"simple\",\n","    \"num_classes\": 6,\n","}\n","\n","model = CNNDetector(model_config).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Training and Testing\n","\n","Validation is done every `test_step` to check if model is overfitting on training data.\n","\n","Testing is done at the end of every epoch with the model produced by that epoch.\n","\n","Training and testing metrics can be viewed in tensorboard as mentioned in the README."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T02:39:35.310349Z","iopub.status.busy":"2024-04-14T02:39:35.309988Z","iopub.status.idle":"2024-04-14T02:39:35.324053Z","shell.execute_reply":"2024-04-14T02:39:35.322936Z","shell.execute_reply.started":"2024-04-14T02:39:35.310321Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def validate(model, valid_dataloader):\n","\n","    model.eval()\n","\n","    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n","\n","    loss = torch.tensor([0.]).to(device)\n","\n","    for batch in tqdm(valid_dataloader):\n","\n","        for key in batch:\n","\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","        \n","        predictions = F.log_softmax(predictions,dim=1)\n","\n","        loss += loss_fn(predictions,batch[\"label\"])\n","\n","    loss = loss / len(valid_dataloader)\n","\n","    model.train()\n","\n","    print(\"Validation loss\", loss.item())\n","\n","    return loss.item()\n","\n","@torch.no_grad()\n","def test(model, test_dataloader):\n","\n","    model.eval()\n","\n","    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n","\n","    num_classes = 6\n","\n","    acc = MulticlassAccuracy(average=\"macro\", num_classes=num_classes)\n","    f1_score = torch.tensor([0.]).to(device)\n","    loss = torch.tensor([0.]).to(device)\n","     \n","    for batch in tqdm(test_dataloader):\n","\n","        for key in batch:\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","\n","        loss += loss_fn(F.log_softmax(predictions, dim=1), batch[\"label\"])\n","\n","        predictions = F.softmax(predictions, dim=1)\n","\n","        predictions = torch.argmax(predictions, dim=1)\n","\n","        classes = torch.argmax(batch[\"label\"], dim=1)\n","\n","        f1_score += multiclass_f1_score(predictions, classes, num_classes=num_classes)\n","\n","        acc.update(predictions, classes)\n","\n","    model.train()\n","\n","    f1_score /= len(test_dataloader)\n","    loss /= len(test_dataloader)\n","\n","    return acc.compute(), f1_score, loss\n","\n","#training\n","\n","def train_epoch(model=None,\n","          train_dataloader=None,\n","          valid_dataloader=None,\n","          test_dataloader=None,\n","          optimiser = None,\n","          train_config=None,\n","          valid_config=None,\n","          lr_scheduler=None,\n","          min_valid_loss=100.,\n","          min_test_loss=100.,\n","          model_name=\"model\",\n","          epoch=0,\n","          logger=None):\n","    \n","    \"\"\"\n","    Training Function\n","    \"\"\"\n","\n","    assert(train_dataloader is not None)\n","    \n","    assert(model is not None)\n","\n","    #Training Params\n","\n","    save_model = train_config.get(\"save_model\", True)\n","    to_model_keys = [\"spec\", \"eeg\", \"label\"]\n","    valid_step = valid_config.get(\"valid_step\", 1000)\n","    verbose_step = train_config.get(\"verbose_step\", 10)\n","    \n","    \n","    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n","    \n","    model.train()\n","    \n","    for itr, batch in tqdm(enumerate(train_dataloader)):\n","\n","#       print(batch[\"eeg\"].shape)\n","\n","        #Train One Iteration\n","\n","        #Load data to GPU\n","\n","        for key in to_model_keys:\n","\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","        \n","        predictions = F.log_softmax(predictions,dim=1)\n","\n","        loss = loss_fn(predictions,batch[\"label\"])\n","        \n","        optimiser.zero_grad()\n","\n","        loss.backward()\n","\n","        optimiser.step()\n","        \n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","        \n","        if itr%verbose_step==0:\n","            print(f\"Training itr {itr}/{len(train_dataloader)}\")\n","            for param_group in optimiser.param_groups:\n","                lr = param_group['lr']\n","                break\n","            print(\"Training Loss: \", loss.item(), \"Learning Rate:\", lr)\n","\n","            logger.log_metrics({\"train/loss\":loss, \"train/lr\": lr}, itr+epoch*len(train_dataloader))\n","        \n","        #Validation\n","        \n","        if itr%valid_step==0 and itr>0 and valid_dataloader is not None:\n","            print(\"Validation\")\n","            valid_loss = validate(model, valid_dataloader)\n","            \n","            if valid_loss < min_valid_loss and save_model:\n","                min_valid_loss = valid_loss\n","                save_path = os.path.join(DATA_ROOT,\"models\")\n","                os.makedirs(save_path, exist_ok=True)\n","                torch.save(model.state_dict(), os.path.join(save_path, f\"{model_name}_best.pt\"))\n","            logger.log_metrics({\"valid/loss\":valid_loss}, itr+epoch*len(train_dataloader))\n","        \n","    #Test\n","    if test_dataloader is not None:\n","        acc, f1_score, loss = test(model, test_dataloader)\n","        if loss < min_test_loss:\n","            min_test_loss = loss\n","        logger.log_metrics({\"test/acc\":acc, \"test/f1_score\":f1_score, \"test/loss\":loss}, itr+epoch*len(train_dataloader))\n","    return min_valid_loss, min_test_loss"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def train(model=None,\n","          optimiser=None,\n","          lr_scheduler=None,\n","          train_config=None,\n","          valid_config=None,\n","          test_dataloader=None,\n","          model_name=\"model\",\n","          logger=None):\n","    \n","    train_batch_size = train_config.get(\"batch_size\", 32)\n","    num_epochs = train_config.get(\"num_epochs\", 10)\n","    valid_folds = train_config.get(\"valid_folds\", 5)\n","    valid_batch_size = valid_config.get(\"batch_size\", 32)\n","    train_workers = train_config.get(\"workers\", 1)\n","    valid_workers = valid_config.get(\"workers\", 1)\n","\n","    min_valid_loss = 100.\n","    min_test_loss = 100.\n","\n","    for epoch in range(num_epochs):\n","\n","        print(\"Epoch\", epoch)\n","\n","        #KGFolds\n","        fold = np.random.randint(valid_folds)\n","        train_df_fold = train_df[train_df[\"fold\"]!=fold]\n","        valid_df = train_df[train_df[\"fold\"]==fold]\n","        train_dataset = HMSDataset(train_df_fold, aug=True)\n","        valid_dataset = HMSDataset(valid_df, aug=False)\n","\n","        train_dataloader = DataLoader(\n","            dataset=train_dataset,\n","            batch_size = train_batch_size,\n","            shuffle=True,\n","            num_workers=train_workers,\n","            collate_fn=train_dataset.collate_fn\n","        )\n","\n","        valid_dataloader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size = valid_batch_size,\n","            shuffle=True,\n","            num_workers=valid_workers,\n","            collate_fn=valid_dataset.collate_fn\n","        )\n","\n","        min_valid_loss, min_test_loss = train_epoch(model=model,\n","                    train_dataloader=train_dataloader,\n","                    valid_dataloader=valid_dataloader,\n","                    test_dataloader=test_dataloader,\n","                    optimiser=optimiser,\n","                    train_config=train_config,\n","                    valid_config=valid_config,\n","                    lr_scheduler=lr_scheduler,\n","                    min_valid_loss=min_valid_loss,\n","                    min_test_loss=min_test_loss,\n","                    model_name=model_name,\n","                    epoch=epoch,\n","                    logger=logger)\n","        print(\"Min Valid Loss\", min_valid_loss, \"Min Test Loss\", min_test_loss)"]},{"cell_type":"markdown","metadata":{},"source":["#### Hyperparameters\n","\n","Configuration of hyperparamters for training and validation/testing is shown below."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T02:39:35.801324Z","iopub.status.busy":"2024-04-14T02:39:35.800510Z","iopub.status.idle":"2024-04-14T02:56:53.096301Z","shell.execute_reply":"2024-04-14T02:56:53.094732Z","shell.execute_reply.started":"2024-04-14T02:39:35.801292Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dee501ab371b4896adedab9d6a1b7c5f","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training itr 0/1202\n","Training Loss:  1.4071985483169556 Learning Rate: 4.0000718651559374e-05\n","Training itr 100/1202\n","Training Loss:  0.8758535981178284 Learning Rate: 4.731232458808946e-05\n","Training itr 200/1202\n","Training Loss:  0.9276068210601807 Learning Rate: 6.874272265430651e-05\n","Training itr 300/1202\n","Training Loss:  1.0700860023498535 Learning Rate: 0.00010365180448417455\n","Training itr 400/1202\n","Training Loss:  1.002517819404602 Learning Rate: 0.00015099686451240733\n","Training itr 500/1202\n","Training Loss:  0.7169563174247742 Learning Rate: 0.0002093637447321907\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53e4b92a58774f46a53467965c6b8de3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1545: RuntimeWarning: invalid value encountered in subtract\n","  np.subtract(arr, avg, out=arr, casting='unsafe')\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in subtract\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss 1.1432820558547974\n","Training itr 600/1202\n","Training Loss:  0.668945848941803 Learning Rate: 0.00027700907443185254\n","Training itr 700/1202\n","Training Loss:  0.7894634008407593 Learning Rate: 0.0003519123432442852\n","Training itr 800/1202\n","Training Loss:  0.8922998905181885 Learning Rate: 0.00043183625212995895\n","Training itr 900/1202\n","Training Loss:  0.7074231505393982 Learning Rate: 0.0005143935396592931\n","Training itr 1000/1202\n","Training Loss:  0.5392115116119385 Learning Rate: 0.0005971182875482926\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a70d77f584dc46b68e7bc099e2aa021f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1545: RuntimeWarning: invalid value encountered in subtract\n","  np.subtract(arr, avg, out=arr, casting='unsafe')\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in subtract\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss 0.9791955947875977\n","Training itr 1100/1202\n","Training Loss:  0.8486787676811218 Learning Rate: 0.0006775395756097369\n","Training itr 1200/1202\n","Training Loss:  0.6995716691017151 Learning Rate: 0.0007532552861071061\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff07e183a9ef406b8711074dbea6f334","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/167 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Min Valid Loss 0.9791955947875977 Min Test Loss tensor([1.0677], device='cuda:0')\n","Epoch 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ac6775464cb44c0a321724a4747e469","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training itr 0/1202\n","Training Loss:  0.9405093789100647 Learning Rate: 0.0007547057640276813\n"]},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1545: RuntimeWarning: invalid value encountered in subtract\n","  np.subtract(arr, avg, out=arr, casting='unsafe')\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in subtract\n"]},{"name":"stdout","output_type":"stream","text":["Training itr 100/1202\n","Training Loss:  0.6319909691810608 Learning Rate: 0.0008232932413689126\n","Training itr 200/1202\n","Training Loss:  0.5581968426704407 Learning Rate: 0.0008828215990165849\n","Training itr 300/1202\n","Training Loss:  0.5922495126724243 Learning Rate: 0.0009315127738834456\n","Training itr 400/1202\n","Training Loss:  0.64671790599823 Learning Rate: 0.0009679124006194855\n","Training itr 500/1202\n","Training Loss:  0.556000828742981 Learning Rate: 0.0009909332523088843\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a62c724e58c4c488093b83dacb31113","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss 0.7835639119148254\n","Training itr 600/1202\n","Training Loss:  0.6133100986480713 Learning Rate: 0.000999887715043859\n","Training itr 700/1202\n","Training Loss:  0.5110162496566772 Learning Rate: 0.0009989488189705994\n","Training itr 800/1202\n","Training Loss:  0.6439278721809387 Learning Rate: 0.000995179222721968\n","Training itr 900/1202\n","Training Loss:  0.42979896068573 Learning Rate: 0.0009886904512612289\n","Training itr 1000/1202\n","Training Loss:  0.5818831324577332 Learning Rate: 0.0009795181364908678\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ace2fe27c5ba4921901d250c9390afda","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss 0.8320747017860413\n","Training itr 1100/1202\n","Training Loss:  0.48330605030059814 Learning Rate: 0.0009677126465009682\n","Training itr 1200/1202\n","Training Loss:  0.6333762407302856 Learning Rate: 0.0009533388089820503\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7349c5ba794406fa0ae3aeefc56b9c2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/167 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Min Valid Loss 0.7835639119148254 Min Test Loss tensor([0.9174], device='cuda:0')\n","Epoch 2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83ef5ca6abed41058b3376d00f9c4186","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training itr 0/1202\n","Training Loss:  0.4596954584121704 Learning Rate: 0.0009530256538704397\n","Training itr 100/1202\n","Training Loss:  0.49300381541252136 Learning Rate: 0.0009361135115920281\n","Training itr 200/1202\n","Training Loss:  0.4745562672615051 Learning Rate: 0.0009168065426583897\n","Training itr 300/1202\n","Training Loss:  0.4941520094871521 Learning Rate: 0.0008952107677605748\n","Training itr 400/1202\n","Training Loss:  0.355582594871521 Learning Rate: 0.000871444776149247\n","Training itr 500/1202\n","Training Loss:  0.27171337604522705 Learning Rate: 0.000845639074423489\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b177c24474c453a8be225460584060a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1545: RuntimeWarning: invalid value encountered in subtract\n","  np.subtract(arr, avg, out=arr, casting='unsafe')\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in subtract\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss 0.6541392207145691\n","Training itr 600/1202\n","Training Loss:  0.3697245121002197 Learning Rate: 0.0008179353698776673\n","Training itr 700/1202\n","Training Loss:  0.31951791048049927 Learning Rate: 0.0007884857923417252\n","Training itr 800/1202\n","Training Loss:  0.524151086807251 Learning Rate: 0.0007574520587880278\n","Training itr 900/1202\n","Training Loss:  0.39750880002975464 Learning Rate: 0.0007250045852921661\n","Training itr 1000/1202\n","Training Loss:  0.433972030878067 Learning Rate: 0.0006913215512242259\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f165f3a01a38495fb66848a0e6cfccab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1545: RuntimeWarning: invalid value encountered in subtract\n","  np.subtract(arr, avg, out=arr, casting='unsafe')\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in subtract\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss 0.70098876953125\n","Training itr 1100/1202\n","Training Loss:  0.4093671441078186 Learning Rate: 0.0006565879208093442\n","Training itr 1200/1202\n","Training Loss:  0.29779481887817383 Learning Rate: 0.000620994427430473\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4939439daca3406e9add04b12d541496","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/167 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Min Valid Loss 0.6541392207145691 Min Test Loss tensor([0.9174], device='cuda:0')\n","Epoch 3\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96ba01b02d824aef9d065f17a0734b3a","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training itr 0/1202\n","Training Loss:  0.32776200771331787 Learning Rate: 0.0006202751224848331\n","Training itr 100/1202\n","Training Loss:  0.25582805275917053 Learning Rate: 0.0005840059536779711\n","Training itr 200/1202\n","Training Loss:  0.21456320583820343 Learning Rate: 0.0005472754925133859\n","Training itr 300/1202\n","Training Loss:  0.3157636225223541 Learning Rate: 0.0005102854376051195\n","Training itr 400/1202\n","Training Loss:  0.4657280147075653 Learning Rate: 0.00047323891307880924\n","Training itr 500/1202\n","Training Loss:  0.18931114673614502 Learning Rate: 0.00043633935315267897\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0288e1c7ca4a4ef4bb7b65f842cedfc8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1545: RuntimeWarning: invalid value encountered in subtract\n","  np.subtract(arr, avg, out=arr, casting='unsafe')\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in subtract\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss 0.7153773903846741\n","Training itr 600/1202\n","Training Loss:  0.2605585753917694 Learning Rate: 0.00039978938501571213\n","Training itr 700/1202\n","Training Loss:  0.414374977350235 Learning Rate: 0.00036378971613747907\n","Training itr 800/1202\n","Training Loss:  0.43289846181869507 Learning Rate: 0.0003285380321197522\n","Training itr 900/1202\n","Training Loss:  0.3011932671070099 Learning Rate: 0.00029422791114215596\n","Training itr 1000/1202\n","Training Loss:  0.25896281003952026 Learning Rate: 0.00026104776096297507\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a42400f0094445a088d9e622cdf9eb4d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1545: RuntimeWarning: invalid value encountered in subtract\n","  np.subtract(arr, avg, out=arr, casting='unsafe')\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in subtract\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss 0.735427975654602\n","Training itr 1100/1202\n","Training Loss:  0.4116417169570923 Learning Rate: 0.00022917978431238623\n","Training itr 1200/1202\n","Training Loss:  0.28191816806793213 Learning Rate: 0.00019879897835946734\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f40c31567524443817f324c0c75f5de","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/167 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Min Valid Loss 0.6541392207145691 Min Test Loss tensor([0.9174], device='cuda:0')\n","Epoch 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d34cb11dbd244f8a99e8e17b5d5edea8","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training itr 0/1202\n","Training Loss:  0.36982303857803345 Learning Rate: 0.00019820769186297346\n"]},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1545: RuntimeWarning: invalid value encountered in subtract\n","  np.subtract(arr, avg, out=arr, casting='unsafe')\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in subtract\n"]},{"name":"stdout","output_type":"stream","text":["Training itr 100/1202\n","Training Loss:  0.3076062798500061 Learning Rate: 0.00016951560806295973\n","Training itr 200/1202\n","Training Loss:  0.36105018854141235 Learning Rate: 0.0001426383298793154\n","Training itr 300/1202\n","Training Loss:  0.35199475288391113 Learning Rate: 0.00011772344897266662\n","Training itr 400/1202\n","Training Loss:  0.41299915313720703 Learning Rate: 9.490778085767242e-05\n","Training itr 500/1202\n","Training Loss:  0.41763240098953247 Learning Rate: 7.431661360563149e-05\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6bd246ecd234f3aae1fe3a93fe04f98","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss 0.24429160356521606\n","Training itr 600/1202\n","Training Loss:  0.28014373779296875 Learning Rate: 5.606301984793902e-05\n","Training itr 700/1202\n","Training Loss:  0.2789078950881958 Learning Rate: 4.0247235858397865e-05\n","Training itr 800/1202\n","Training Loss:  0.3973802626132965 Learning Rate: 2.695611112404248e-05\n","Training itr 900/1202\n","Training Loss:  0.3737504482269287 Learning Rate: 1.62626314270539e-05\n","Training itr 1000/1202\n","Training Loss:  0.22196350991725922 Learning Rate: 8.225518056677635e-06\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"faa56f64ee144f21878acae04bba29a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss 0.24075496196746826\n","Training itr 1100/1202\n","Training Loss:  0.3446682095527649 Learning Rate: 2.888905351996413e-06\n","Training itr 1200/1202\n","Training Loss:  0.25690239667892456 Learning Rate: 2.820983462736311e-07\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b130241aece24448af0d862e716a0bab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/167 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Min Valid Loss 0.24075496196746826 Min Test Loss tensor([0.9174], device='cuda:0')\n"]}],"source":["train_config = {\n","    \"batch_size\": 32,\n","    \"num_epochs\": 5,\n","    \"lr\": 1e-3,\n","    \"valid_folds\":5,\n","    \"save_model\": True,\n","    \"workers\": 1,\n","    \"verbose_step\": 100,\n","    \"weight_decay\": 1e-4,\n","    \"valid_folds\": 5,\n","}\n","\n","valid_config = {\n","    \"batch_size\": 32,\n","    \"workers\": 1,\n","    \"valid_step\": 500\n","}\n","\n","lr = train_config.get(\"lr\", 1e-3)\n","weight_decay = train_config.get(\"weight_decay\", 0.)\n","model_name = model_config.get(\"model_name\", \"efficientnet_b0\")\n","num_epochs = train_config.get(\"num_epochs\", 1)\n","folds = train_config.get(\"valid_folds\", 5)\n","train_batch_size = train_config.get(\"batch_size\", 32)\n","test_batch_size = valid_config.get(\"batch_size\", 32)\n","\n","\n","logger = TensorBoardLogger(f\"logs/{model_name}\", name=model_name)\n","\n","optimiser = torch.optim.Adam(\n","model.parameters(),\n","lr=lr,\n","weight_decay=weight_decay\n",")\n","\n","lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","    optimiser,\n","    max_lr=lr,\n","    epochs=num_epochs,\n","    steps_per_epoch=int((folds-1)/folds*train_df.shape[0]/train_batch_size)+10\n",")\n","\n","test_dataset = HMSDataset(df=test_df)\n","\n","test_dataloader = DataLoader(\n","    dataset=test_dataset,\n","    batch_size=test_batch_size,\n","    collate_fn=test_dataset.collate_fn\n",")\n","\n","torch.cuda.empty_cache()\n","\n","train(model=model,\n","      train_config=train_config,\n","      valid_config=valid_config,\n","      test_dataloader=test_dataloader,\n","      model_name=model_name,\n","      optimiser=optimiser,\n","      lr_scheduler=lr_scheduler,\n","      logger=logger)\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
