{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-14T05:18:43.921801Z","iopub.status.busy":"2024-04-14T05:18:43.921227Z","iopub.status.idle":"2024-04-14T05:18:52.582521Z","shell.execute_reply":"2024-04-14T05:18:52.581567Z","shell.execute_reply.started":"2024-04-14T05:18:43.921765Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.models import efficientnet_b0\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from sklearn.model_selection import KFold, GroupKFold, train_test_split\n","from datetime import datetime\n","from tqdm import tqdm\n","import albumentations as A\n","import gc\n","import matplotlib.pyplot as plt\n","import math\n","import multiprocessing\n","import os\n","import time\n","import random\n","from typing import List, Tuple, Union\n","import pickle\n","from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#Kaggle\n","# DATA_ROOT = \"/kaggle/input/hms-harmful-brain-activity-classification/\"\n","# TRAIN_EEG = \"train_eegs\"\n","# TRAIN_SPEC = \"train_spectrograms\"\n","# TEST_EEG = \"test_eegs\"\n","# TEST_SPEC = \"test_spectrograms\"\n","\n","#Local\n","DATA_ROOT = \"/home/benluo/HBAC/data/hbac\"\n","TRAIN_EEG = \"train_eegs\"\n","TRAIN_SPEC = \"train_spectrograms\"\n","TEST_EEG = \"test_eegs\"\n","TEST_SPEC = \"test_spectrograms\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:18:52.584370Z","iopub.status.busy":"2024-04-14T05:18:52.583950Z","iopub.status.idle":"2024-04-14T05:18:52.616226Z","shell.execute_reply":"2024-04-14T05:18:52.615329Z","shell.execute_reply.started":"2024-04-14T05:18:52.584344Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["train_list = pd.read_csv(os.path.join(DATA_ROOT, \"train.csv\"))\n","\n","train_list_reduced = train_list.iloc[:train_list.shape[0]//2,:]\n","\n","train_list_reduced.to_csv(os.path.join(DATA_ROOT, \"train_reduced.csv\"))"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def generate_data(val_folds:int = 5,\n","                  test_size:float = 0.2,\n","                  saved_spec:str = \"all_spec.pkl\",\n","                  saved_eeg:str = \"all_eeg.pkl\"):\n","\n","    train_list = pd.read_csv(os.path.join(DATA_ROOT, \"train_reduced.csv\"))\n","\n","    print(\"All data\")\n","    display(train_list.head())\n","\n","    # test_df = pd.read_csv(os.path.join(DATA_ROOT, \"test.csv\"))\n","\n","    label_cols = train_list.columns[-6:]\n","    \n","\n","    #Select first eeg and spectrogram in each spectrogram file\n","    train_df = train_list[['spectrogram_id','eeg_id','patient_id','spectrogram_label_offset_seconds','eeg_label_offset_seconds']]\n","\n","    aux = train_list[label_cols].copy()\n","    \n","    for label in label_cols:\n","        train_df[label] = aux[label].values\n","        \n","    y_data = train_df[label_cols].values\n","    y_data = y_data / y_data.sum(axis=1,keepdims=True)\n","    train_df[label_cols] = y_data\n","\n","    aux = train_list['expert_consensus'].copy()\n","    train_df['target'] = aux\n","    train_df = train_df.reset_index()\n","\n","    train_df = train_df.sort_values(\"patient_id\")\n","\n","    test_df = train_df.iloc[int(0.9*train_df.shape[0]):]\n","\n","    train_df = train_df.iloc[:int(0.9*train_df.shape[0])]\n","\n","    train_df = train_df.reset_index()\n","    test_df = test_df.reset_index()\n","\n","    print(\"Training data\")\n","    display(train_df.head())\n","\n","    print(\"Testing data\")\n","    display(test_df.head())\n","\n","\n","    gkf = GroupKFold(n_splits=val_folds)\n","\n","    #KFold grouped by patient ID\n","    for fold, (train_index, val_index) in enumerate(gkf.split(train_df, train_df.target, train_df.patient_id)):\n","        train_df.loc[val_index, \"fold\"] = int(fold)\n","    \n","    all_eeg = {}\n","    \n","    all_spec = {}\n","\n","\n","    try:\n","\n","        with open(os.path.join(DATA_ROOT,saved_spec), \"rb\") as handle:\n","            all_spec = pickle.load(handle)\n","\n","        with open(os.path.join(DATA_ROOT,saved_eeg), \"rb\") as handle:\n","            all_eeg = pickle.load(handle)\n","\n","    except:\n","    \n","        for idx, row in tqdm(train_list.iterrows()):\n","\n","            spec_id = row[\"spectrogram_id\"]\n","            eeg_id = row[\"eeg_id\"]\n","\n","            if spec_id not in all_spec:\n","\n","                spec = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_SPEC, str(spec_id)+\".parquet\"))\n","\n","                all_spec[spec_id] = spec.iloc[:,1:].values.astype(dtype=np.float32)\n","\n","            if eeg_id not in all_eeg:\n","\n","                eeg = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_EEG, str(eeg_id)+\".parquet\"))\n","\n","                all_eeg[eeg_id] = eeg.iloc[:,1:].values.astype(dtype=np.float32)\n","        \n","        with open(os.path.join(DATA_ROOT, saved_eeg), \"wb\") as handle:\n","            pickle.dump(all_eeg, handle)\n","        \n","        with open(os.path.join(DATA_ROOT, saved_spec), \"wb\") as handle:\n","            pickle.dump(all_spec, handle)\n","    \n","    # for i, row in tqdm(test_df.iterrows()):\n","            \n","    #     eeg_id = row[\"eeg_id\"]\n","    #     spec_id = row[\"spectrogram_id\"]\n","\n","    #     if eeg_id not in test_eeg:\n","\n","    #         eeg = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_EEG, str(eeg_id)+\".parquet\"))\n","\n","\n","    #     if spec_id not in test_spec:\n","    \n","    #         spec = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_SPEC, str(spec_id)+\".parquet\"))\n","        \n","    #     test_eeg[eeg_id] = eeg.iloc[:,1:].values.astype(dtype=np.float16)\n","    #     test_spec[spec_id] = spec.iloc[:,1:].values.astype(dtype=np.float16)\n","    \n","    return train_df, test_df, all_eeg, all_spec, label_cols"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All data\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>eeg_id</th>\n","      <th>eeg_sub_id</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>spectrogram_id</th>\n","      <th>spectrogram_sub_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>label_id</th>\n","      <th>patient_id</th>\n","      <th>expert_consensus</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1628180742</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>353733</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>127492639</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1628180742</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>353733</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>3887563113</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1628180742</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>353733</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>1142670488</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1628180742</td>\n","      <td>3</td>\n","      <td>18.0</td>\n","      <td>353733</td>\n","      <td>3</td>\n","      <td>18.0</td>\n","      <td>2718991173</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1628180742</td>\n","      <td>4</td>\n","      <td>24.0</td>\n","      <td>353733</td>\n","      <td>4</td>\n","      <td>24.0</td>\n","      <td>3080632009</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0      eeg_id  eeg_sub_id  eeg_label_offset_seconds  \\\n","0           0  1628180742           0                       0.0   \n","1           1  1628180742           1                       6.0   \n","2           2  1628180742           2                       8.0   \n","3           3  1628180742           3                      18.0   \n","4           4  1628180742           4                      24.0   \n","\n","   spectrogram_id  spectrogram_sub_id  spectrogram_label_offset_seconds  \\\n","0          353733                   0                               0.0   \n","1          353733                   1                               6.0   \n","2          353733                   2                               8.0   \n","3          353733                   3                              18.0   \n","4          353733                   4                              24.0   \n","\n","     label_id  patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  \\\n","0   127492639       42516          Seizure             3         0         0   \n","1  3887563113       42516          Seizure             3         0         0   \n","2  1142670488       42516          Seizure             3         0         0   \n","3  2718991173       42516          Seizure             3         0         0   \n","4  3080632009       42516          Seizure             3         0         0   \n","\n","   lrda_vote  grda_vote  other_vote  \n","0          0          0           0  \n","1          0          0           0  \n","2          0          0           0  \n","3          0          0           0  \n","4          0          0           0  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training data\n"]},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self[col] = igetitem(value, i)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>level_0</th>\n","      <th>index</th>\n","      <th>spectrogram_id</th>\n","      <th>eeg_id</th>\n","      <th>patient_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>41744</td>\n","      <td>41744</td>\n","      <td>802850878</td>\n","      <td>1873660287</td>\n","      <td>56</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>49045</td>\n","      <td>49045</td>\n","      <td>957002006</td>\n","      <td>165634434</td>\n","      <td>56</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41746</td>\n","      <td>41746</td>\n","      <td>802850878</td>\n","      <td>2057577408</td>\n","      <td>56</td>\n","      <td>290.0</td>\n","      <td>46.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>41745</td>\n","      <td>41745</td>\n","      <td>802850878</td>\n","      <td>2057577408</td>\n","      <td>56</td>\n","      <td>244.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>25278</td>\n","      <td>25278</td>\n","      <td>497667405</td>\n","      <td>374550767</td>\n","      <td>56</td>\n","      <td>694.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   level_0  index  spectrogram_id      eeg_id  patient_id  \\\n","0    41744  41744       802850878  1873660287          56   \n","1    49045  49045       957002006   165634434          56   \n","2    41746  41746       802850878  2057577408          56   \n","3    41745  41745       802850878  2057577408          56   \n","4    25278  25278       497667405   374550767          56   \n","\n","   spectrogram_label_offset_seconds  eeg_label_offset_seconds  seizure_vote  \\\n","0                               0.0                       0.0           0.0   \n","1                               0.0                       0.0           0.0   \n","2                             290.0                      46.0           0.0   \n","3                             244.0                       0.0           0.0   \n","4                             694.0                       0.0           0.0   \n","\n","   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote target  \n","0       0.0       0.0        0.0        0.0         1.0  Other  \n","1       0.0       0.0        0.0        0.0         1.0  Other  \n","2       0.0       0.0        0.0        0.0         1.0  Other  \n","3       0.0       0.0        0.0        0.0         1.0  Other  \n","4       0.0       0.0        0.0        0.0         1.0  Other  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Testing data\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>level_0</th>\n","      <th>index</th>\n","      <th>spectrogram_id</th>\n","      <th>eeg_id</th>\n","      <th>patient_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5410</td>\n","      <td>5410</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>122.0</td>\n","      <td>122.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5389</td>\n","      <td>5389</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>72.0</td>\n","      <td>72.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5384</td>\n","      <td>5384</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>60.0</td>\n","      <td>60.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5394</td>\n","      <td>5394</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>82.0</td>\n","      <td>82.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5385</td>\n","      <td>5385</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>62.0</td>\n","      <td>62.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   level_0  index  spectrogram_id      eeg_id  patient_id  \\\n","0     5410   5410        91996359  3686473557       57272   \n","1     5389   5389        91996359  3686473557       57272   \n","2     5384   5384        91996359  3686473557       57272   \n","3     5394   5394        91996359  3686473557       57272   \n","4     5385   5385        91996359  3686473557       57272   \n","\n","   spectrogram_label_offset_seconds  eeg_label_offset_seconds  seizure_vote  \\\n","0                             122.0                     122.0           0.0   \n","1                              72.0                      72.0           0.0   \n","2                              60.0                      60.0           0.0   \n","3                              82.0                      82.0           0.0   \n","4                              62.0                      62.0           0.0   \n","\n","   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote target  \n","0       0.0       0.0        1.0        0.0         0.0   LRDA  \n","1       0.0       0.0        1.0        0.0         0.0   LRDA  \n","2       0.0       0.0        1.0        0.0         0.0   LRDA  \n","3       0.0       0.0        1.0        0.0         0.0   LRDA  \n","4       0.0       0.0        1.0        0.0         0.0   LRDA  "]},"metadata":{},"output_type":"display_data"}],"source":["train_df, test_df, all_eeg, all_spec, label_cols = generate_data()"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:37:19.304302Z","iopub.status.busy":"2024-04-14T05:37:19.303853Z","iopub.status.idle":"2024-04-14T05:37:19.335251Z","shell.execute_reply":"2024-04-14T05:37:19.334018Z","shell.execute_reply.started":"2024-04-14T05:37:19.304270Z"},"trusted":true},"outputs":[],"source":["#data processing\n","class HMSDataset(Dataset):\n","\n","    def __init__(self,\n","                 df:pd.DataFrame = None,\n","                 aug: bool = False) -> None:\n","        \n","\n","        super(HMSDataset, self).__init__()\n","\n","        self.df = df\n","\n","        #Data augmentation\n","        self.aug = aug\n","\n","        self.eeg_sample_freq = 200 # 200 Hz\n","        self.spec_sample_freq = 0.5 # 0.5 Hz\n","    \n","        \n","        #data augmentation\n","        self.transforms = A.Compose([\n","            A.HorizontalFlip(p=0.5)\n","        ])\n","\n","    def format_data(self, eeg:np.array, spec:np.array) -> Tuple[torch.tensor]:\n","\n","        eps = 1e-6\n","\n","        eeg = eeg.astype(dtype=np.float32)\n","        spec = spec.astype(dtype=np.float32)\n","\n","        #Normalizing and getting rid of Nans\n","        eeg_mean = np.nanmean(eeg.flatten())\n","        eeg_std = np.nanstd(eeg.flatten())\n","        eeg = (eeg-eeg_mean)/(eeg_std+eps)\n","        eeg = np.nan_to_num(eeg, nan=0.0)\n","\n","        #Normalizing and getting rid of Nans\n","        spec = np.clip(spec, np.exp(-4), np.exp(8))\n","        spec = np.log(spec)\n","        \n","        spec_mean = np.nanmean(spec.flatten())\n","        spec_std = np.nanstd(spec.flatten())\n","        spec = (spec-spec_mean)/(spec_std+eps)\n","        spec = np.nan_to_num(spec, nan=0.0)\n","        \n","        if self.aug:\n","\n","            eeg = self.transforms(image=eeg)[\"image\"]\n","            spec = self.transforms(image=spec)[\"image\"]\n","\n","        eeg = torch.tensor(eeg.copy())\n","        spec = torch.tensor(spec.copy())\n","\n","        return eeg, spec\n","\n","\n","    def __getitem__(self, index) -> dict:\n","    \n","        row = self.df.iloc[index]\n","\n","        eeg_id = row[\"eeg_id\"]\n","        spec_id = row[\"spectrogram_id\"]\n","\n","        #EEG Sub-sampling\n","        start = int(row[\"eeg_label_offset_seconds\"]*self.eeg_sample_freq)\n","        end = int((row[\"eeg_label_offset_seconds\"]+50)*self.eeg_sample_freq)\n","        eeg = all_eeg[eeg_id][start:end]\n","        \n","        #Spectrogram Sub-sampling\n","        start = int(row[\"spectrogram_label_offset_seconds\"]*self.spec_sample_freq)\n","        end = int((row[\"spectrogram_label_offset_seconds\"]+600)*self.spec_sample_freq)\n","        spec = all_spec[spec_id][start:end].T\n","\n","        # print(all_eeg[eeg_id].shape, eeg.shape, all_spec[spec_id].shape, spec.shape)\n","\n","        eeg, spec = self.format_data(eeg, spec)\n","\n","        label = torch.tensor(row[label_cols], dtype=torch.float32)\n","\n","        return eeg, spec, label\n","\n","\n","    def __len__(self):\n","\n","        return self.df.shape[0]\n","\n","    @staticmethod\n","    def collate_fn(batch):\n","\n","        eeg, spec, label = zip(*batch)\n","        \n","        if eeg is not None:\n","            eeg = torch.stack(eeg, dim=0).float().unsqueeze(1)\n","        \n","        if spec is not None:\n","            spec = torch.stack(spec, dim=0).float().unsqueeze(1).expand(-1,3,-1,-1)\n","\n","        if label is not None:            \n","            label = torch.stack(label, dim=0)\n","        \n","        return {\n","            \"eeg\": eeg,\n","            \"spec\": spec,\n","            \"label\": label\n","        }\n","    "]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:27:07.257131Z","iopub.status.busy":"2024-04-14T05:27:07.256459Z","iopub.status.idle":"2024-04-14T05:27:07.264525Z","shell.execute_reply":"2024-04-14T05:27:07.263436Z","shell.execute_reply.started":"2024-04-14T05:27:07.257100Z"},"trusted":true},"outputs":[],"source":["class CNNDetector(nn.Module):\n","\n","    def __init__(self, config={}):\n","\n","        super(CNNDetector, self).__init__()\n","\n","        self.backbone_1d = None\n","\n","        self.backbone_2d = efficientnet_b0(weights=\"IMAGENET1K_V1\")\n","        \n","#         self.backbone_2d.conv1 = nn.Conv2d(config.get(\"in_channels\",1), 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False)\n","        \n","        self.backbone_2d.classifier[1] = nn.Linear(1280, config.get(\"num_classes\", 6))\n","        \n","#         print(self.backbone_2d)\n","\n","        self.head = None\n","\n","    def get_loss(self, pred_dict):\n","\n","        pass\n","\n","    def forward(self, data_dict):\n","\n","        \"\"\"\n","        returns a dictionary pred_dict with the logits for loss calculation and gradient descent.\n","        \"\"\"\n","        \n","#         print(torch.isnan(torch.sum(data_dict[\"spec\"])))\n","\n","        return self.backbone_2d(data_dict[\"spec\"])"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:37:21.120108Z","iopub.status.busy":"2024-04-14T05:37:21.119749Z","iopub.status.idle":"2024-04-14T05:37:21.432607Z","shell.execute_reply":"2024-04-14T05:37:21.431524Z","shell.execute_reply.started":"2024-04-14T05:37:21.120078Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[torch.Size([10000, 19]), torch.Size([400, 300]), torch.Size([6])]\n","(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[ 1.2471,  1.6973,  1.5849,  ...,  1.8333,  1.8392,  1.7302],\n","        [ 1.7592,  1.8029,  1.7645,  ...,  1.8456,  1.9185,  1.8437],\n","        [ 1.6919,  1.8934,  1.7796,  ...,  1.8281,  1.9585,  1.8435],\n","        ...,\n","        [-0.8631, -0.7017, -0.7756,  ..., -1.3022, -1.1080, -1.1080],\n","        [-0.9699, -0.7017, -0.6376,  ..., -0.9699, -0.9699, -0.7756],\n","        [-0.9699, -0.8631, -0.7017,  ..., -0.9699, -1.1080, -1.1080]]), tensor([0.0000, 0.0000, 0.0000, 0.6000, 0.0667, 0.3333]))\n"]},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"]}],"source":["dataset = HMSDataset(df=train_df)\n","batch_size = 32\n","\n","print([data.shape for data in dataset[0]])\n","\n","i = np.random.randint(len(dataset))\n","print(dataset[i])"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T02:39:35.310349Z","iopub.status.busy":"2024-04-14T02:39:35.309988Z","iopub.status.idle":"2024-04-14T02:39:35.324053Z","shell.execute_reply":"2024-04-14T02:39:35.322936Z","shell.execute_reply.started":"2024-04-14T02:39:35.310321Z"},"trusted":true},"outputs":[],"source":["#testing\n","\n","@torch.no_grad()\n","def validate(model, valid_dataloader):\n","\n","    model.eval()\n","\n","    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n","\n","    loss = torch.tensor([0.]).to(device)\n","\n","    for batch in tqdm(valid_dataloader):\n","\n","        for key in batch:\n","\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","        \n","        predictions = F.log_softmax(predictions,dim=1)\n","\n","        loss += loss_fn(predictions,batch[\"label\"])\n","\n","    loss = loss / len(valid_dataloader)\n","\n","    model.train()\n","\n","    print(\"Validation loss\", loss.item())\n","\n","    return loss.item()\n","\n","def test(model, test_dataloader):\n","\n","    model.eval()\n","\n","    correct = 0\n","\n","    for batch in test_dataloader:\n","\n","        for key in batch:\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","\n","        predictions = F.softmax(predictions, dim=1)\n","\n","        predictions = torch.argmax(predictions,dim=1)\n","\n","        classes = torch.argmax(batch[\"label\"], dim=1)\n","\n","        correct += torch.sum(predictions == classes, dtype=torch.int)\n","\n","    model.train()\n","\n","#training\n","\n","def train_epoch(model=None,\n","          train_dataloader=None,\n","          valid_dataloader=None,\n","          optimiser = None,\n","          train_config=None,\n","          valid_config=None,\n","          lr_scheduler=None,\n","          min_valid_loss=100.,\n","          model_name=\"model\",\n","          epoch=0,\n","          logger=None):\n","    \n","    \"\"\"\n","    Training Function\n","    \"\"\"\n","\n","    assert(train_dataloader is not None)\n","    \n","    assert(model is not None)\n","\n","    #Training Params\n","\n","    save_model = train_config.get(\"save_model\", True)\n","    to_model_keys = [\"spec\", \"eeg\", \"label\"]\n","    valid_step = valid_config.get(\"valid_step\", 1000)\n","    verbose_step = train_config.get(\"verbose_step\", 10)\n","    \n","    \n","    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n","    \n","    model.train()\n","    \n","    for itr, batch in tqdm(enumerate(train_dataloader)):\n","\n","#       print(batch[\"eeg\"].shape)\n","\n","        #Train One Iteration\n","\n","        #Load data to GPU\n","\n","        for key in to_model_keys:\n","\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","        \n","        predictions = F.log_softmax(predictions,dim=1)\n","\n","        loss = loss_fn(predictions,batch[\"label\"])\n","        \n","        optimiser.zero_grad()\n","\n","        loss.backward()\n","\n","        optimiser.step()\n","        \n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","        \n","        if itr%verbose_step==0:\n","            print(f\"Training itr {itr}/{len(train_dataloader)}\")\n","            for param_group in optimiser.param_groups:\n","                lr = param_group['lr']\n","                break\n","            print(\"Training Loss: \", loss, \"Learning Rate:\", lr)\n","\n","            logger.log_metrics({\"KLDiv loss\":loss, \"Learning Rate\": lr}, itr+epoch*len(train_dataloader))\n","        \n","        #Test\n","        \n","        if itr%valid_step==0 and itr>0 and valid_dataloader is not None:\n","            print(\"Validation\")\n","            valid_loss = validate(model, valid_dataloader)\n","            \n","            if valid_loss < min_valid_loss and save_model:\n","                min_valid_loss = valid_loss\n","                save_path = os.path.join(DATA_ROOT,\"models\")\n","                os.makedirs(save_path, exist_ok=True)\n","                torch.save(model.state_dict(), os.path.join(save_path, f\"{model_name}_best.pt\"))\n","            logger.log_metrics({\"Valid loss\":valid_loss}, itr+epoch*len(train_dataloader))\n","    return min_valid_loss"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def train(model=None,\n","          optimiser=None,\n","          lr_scheduler=None,\n","          train_config=None,\n","          valid_config=None,\n","          model_name=\"model\",\n","          logger=None):\n","    \n","    train_batch_size = train_config.get(\"batch_size\", 32)\n","    num_epochs = train_config.get(\"num_epochs\", 10)\n","    valid_folds = train_config.get(\"valid_folds\", 5)\n","    valid_batch_size = valid_config.get(\"batch_size\", 32)\n","    train_workers = train_config.get(\"workers\", 1)\n","    valid_workers = valid_config.get(\"workers\", 1)\n","\n","    min_valid_loss = 100\n","\n","    for epoch in range(num_epochs):\n","\n","        print(\"Epoch\", epoch)\n","\n","        #KGFolds\n","        fold = np.random.randint(valid_folds)\n","        train_df_fold = train_df[train_df[\"fold\"]!=fold]\n","        valid_df = train_df[train_df[\"fold\"]==fold]\n","        train_dataset = HMSDataset(train_df_fold, aug=True)\n","        valid_dataset = HMSDataset(valid_df, aug=False)\n","\n","        train_dataloader = DataLoader(\n","            dataset=train_dataset,\n","            batch_size = train_batch_size,\n","            shuffle=True,\n","            num_workers=train_workers,\n","            collate_fn=train_dataset.collate_fn\n","        )\n","\n","        valid_dataloader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size = valid_batch_size,\n","            shuffle=True,\n","            num_workers=valid_workers,\n","            collate_fn=valid_dataset.collate_fn\n","        )\n","\n","        min_valid_loss = train_epoch(model=model,\n","                    train_dataloader=train_dataloader,\n","                    valid_dataloader=valid_dataloader,\n","                    optimiser=optimiser,\n","                    train_config=train_config,\n","                    valid_config=valid_config,\n","                    lr_scheduler=lr_scheduler,\n","                    min_valid_loss=min_valid_loss,\n","                    model_name=model_name,\n","                    epoch=epoch,\n","                    logger=logger)\n","        print(\"Min Valid Loss\", min_valid_loss)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T02:39:35.801324Z","iopub.status.busy":"2024-04-14T02:39:35.800510Z","iopub.status.idle":"2024-04-14T02:56:53.096301Z","shell.execute_reply":"2024-04-14T02:56:53.094732Z","shell.execute_reply.started":"2024-04-14T02:39:35.801292Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["2it [00:00,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 0/1202\n","Training Loss:  tensor(1.6280, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 4.0000718651559374e-05\n"]},{"name":"stderr","output_type":"stream","text":["102it [00:13,  7.93it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 100/1202\n","Training Loss:  tensor(1.0506, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 4.731232458808946e-05\n"]},{"name":"stderr","output_type":"stream","text":["202it [00:26,  7.90it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 200/1202\n","Training Loss:  tensor(1.5770, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 6.874272265430651e-05\n"]},{"name":"stderr","output_type":"stream","text":["302it [00:38,  8.10it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 300/1202\n","Training Loss:  tensor(1.2193, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.00010365180448417455\n"]},{"name":"stderr","output_type":"stream","text":["402it [00:51,  8.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 400/1202\n","Training Loss:  tensor(1.3008, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.00015099686451240733\n"]},{"name":"stderr","output_type":"stream","text":["500it [01:04,  8.12it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 500/1202\n","Training Loss:  tensor(1.2955, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0002093637447321907\n","Validation\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 601/601 [00:19<00:00, 30.28it/s]\n","502it [01:24,  4.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation loss 1.2615526914596558\n"]},{"name":"stderr","output_type":"stream","text":["602it [01:37,  7.94it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 600/1202\n","Training Loss:  tensor(1.1878, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.00027700907443185254\n"]},{"name":"stderr","output_type":"stream","text":["702it [01:50,  7.87it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 700/1202\n","Training Loss:  tensor(1.4017, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0003519123432442852\n"]},{"name":"stderr","output_type":"stream","text":["802it [02:03,  7.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 800/1202\n","Training Loss:  tensor(1.0656, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.00043183625212995895\n"]},{"name":"stderr","output_type":"stream","text":["902it [02:16,  7.69it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 900/1202\n","Training Loss:  tensor(1.3154, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0005143935396592931\n"]},{"name":"stderr","output_type":"stream","text":["1000it [02:29,  8.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 1000/1202\n","Training Loss:  tensor(1.1615, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0005971182875482926\n","Validation\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 601/601 [00:20<00:00, 29.47it/s]\n","1002it [02:49,  4.42s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation loss 1.502281665802002\n"]},{"name":"stderr","output_type":"stream","text":["1102it [03:02,  7.84it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 1100/1202\n","Training Loss:  tensor(0.7862, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0006775395756097369\n"]},{"name":"stderr","output_type":"stream","text":["1202it [03:16,  6.13it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 1200/1202\n","Training Loss:  tensor(2.6702, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0007532552861071061\n","Min Valid Loss 1.2615526914596558\n","Epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","2it [00:00,  5.81it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 0/1202\n","Training Loss:  tensor(2.3752, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0007547057640276813\n"]},{"name":"stderr","output_type":"stream","text":["102it [00:13,  7.83it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 100/1202\n","Training Loss:  tensor(1.1535, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0008232932413689126\n"]},{"name":"stderr","output_type":"stream","text":["202it [00:25,  8.11it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 200/1202\n","Training Loss:  tensor(2.1042, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0008828215990165849\n"]},{"name":"stderr","output_type":"stream","text":["302it [00:38,  8.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 300/1202\n","Training Loss:  tensor(0.5218, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009315127738834456\n"]},{"name":"stderr","output_type":"stream","text":["402it [00:51,  7.61it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 400/1202\n","Training Loss:  tensor(1.6022, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009679124006194855\n"]},{"name":"stderr","output_type":"stream","text":["500it [01:03,  8.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 500/1202\n","Training Loss:  tensor(0.9123, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009909332523088843\n","Validation\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 601/601 [00:20<00:00, 29.40it/s]\n","502it [01:24,  4.42s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation loss 1.7085474729537964\n"]},{"name":"stderr","output_type":"stream","text":["602it [01:37,  7.89it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 600/1202\n","Training Loss:  tensor(1.2700, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.000999887715043859\n"]},{"name":"stderr","output_type":"stream","text":["702it [01:50,  7.88it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 700/1202\n","Training Loss:  tensor(1.6168, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009989488189705994\n"]},{"name":"stderr","output_type":"stream","text":["802it [02:03,  7.32it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 800/1202\n","Training Loss:  tensor(0.8978, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.000995179222721968\n"]},{"name":"stderr","output_type":"stream","text":["902it [02:16,  7.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 900/1202\n","Training Loss:  tensor(1.2873, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009886904512612289\n"]},{"name":"stderr","output_type":"stream","text":["1000it [02:29,  7.70it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 1000/1202\n","Training Loss:  tensor(1.0044, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009795181364908678\n","Validation\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 601/601 [00:20<00:00, 29.27it/s]\n","1002it [02:50,  4.45s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation loss 1.4190058708190918\n"]},{"name":"stderr","output_type":"stream","text":["1102it [03:03,  7.60it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 1100/1202\n","Training Loss:  tensor(0.7039, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009677126465009682\n"]},{"name":"stderr","output_type":"stream","text":["1202it [03:16,  6.13it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 1200/1202\n","Training Loss:  tensor(1.5288, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009533388089820503\n","Min Valid Loss 1.2615526914596558\n","Epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["\n","2it [00:00,  5.42it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 0/1202\n","Training Loss:  tensor(2.0344, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009530256538704397\n"]},{"name":"stderr","output_type":"stream","text":["102it [00:13,  7.20it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 100/1202\n","Training Loss:  tensor(1.1688, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009361135115920281\n"]},{"name":"stderr","output_type":"stream","text":["202it [00:26,  7.17it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 200/1202\n","Training Loss:  tensor(1.2440, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0009168065426583897\n"]},{"name":"stderr","output_type":"stream","text":["302it [00:39,  7.56it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 300/1202\n","Training Loss:  tensor(1.3458, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0008952107677605748\n"]},{"name":"stderr","output_type":"stream","text":["402it [00:52,  7.47it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 400/1202\n","Training Loss:  tensor(0.7685, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.000871444776149247\n"]},{"name":"stderr","output_type":"stream","text":["500it [01:05,  7.82it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 500/1202\n","Training Loss:  tensor(2.1309, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.000845639074423489\n","Validation\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 601/601 [00:20<00:00, 28.62it/s]\n","502it [01:26,  4.55s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation loss 1.297292947769165\n"]},{"name":"stderr","output_type":"stream","text":["602it [01:39,  7.94it/s]"]},{"name":"stdout","output_type":"stream","text":["Training itr 600/1202\n","Training Loss:  tensor(0.8687, device='cuda:0', grad_fn=<DivBackward0>) Learning Rate: 0.0008179353698776673\n"]},{"name":"stderr","output_type":"stream","text":["617it [01:41,  6.07it/s]\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">54</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">55</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_epoch</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">101</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">31</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torchvision/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">effici</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">entnet.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">355</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 352 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> x                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 353 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 354 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x: Tensor) -&gt; Tensor:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 355 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_impl(x)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 356 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 357 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 358 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_efficientnet</span>(                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torchvision/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">effici</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">entnet.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">345</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_forward_impl</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 342 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>nn.init.zeros_(m.bias)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 343 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_forward_impl</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x: Tensor) -&gt; Tensor:                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 345 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.features(x)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 346 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 347 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.avgpool(x)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = torch.flatten(x, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">containe</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">r.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">139</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># with Any as TorchScript expects a more precise type</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>139 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span> = module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">append</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module: Module) -&gt; <span style=\"color: #808000; text-decoration-color: #808000\">'Sequential'</span>:                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">containe</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">r.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">139</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># with Any as TorchScript expects a more precise type</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>139 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span> = module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">append</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module: Module) -&gt; <span style=\"color: #808000; text-decoration-color: #808000\">'Sequential'</span>:                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torchvision/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">effici</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">entnet.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.out_channels = cnf.out_channels                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>result = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.block(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.use_res_connect:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>result = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.stochastic_depth(result)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>result += <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">containe</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">r.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">139</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># with Any as TorchScript expects a more precise type</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>139 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span> = module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">append</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module: Module) -&gt; <span style=\"color: #808000; text-decoration-color: #808000\">'Sequential'</span>:                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">containe</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">r.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">139</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># with Any as TorchScript expects a more precise type</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>139 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span> = module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">append</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module: Module) -&gt; <span style=\"color: #808000; text-decoration-color: #808000\">'Sequential'</span>:                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">batchnor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">m.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">179</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">176 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>bn_training,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>exponential_average_factor,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>179 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.eps,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">181 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">182 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">24</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">39</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">batch_norm</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2436 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_verify_batch_size(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.size())                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2437 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2438 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.batch_norm(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2439 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, weight, bias, running_mean, running_var, training, momentum, eps, torch.b  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2440 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2441 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2442 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"],"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m54\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mtrain\u001b[0m:\u001b[94m55\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mtrain_epoch\u001b[0m:\u001b[94m101\u001b[0m                                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.p\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mforward\u001b[0m:\u001b[94m31\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.p\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torchvision/models/\u001b[0m\u001b[1;33meffici\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33mentnet.py\u001b[0m:\u001b[94m355\u001b[0m in \u001b[92mforward\u001b[0m                                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 352 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m x                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 353 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 354 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, x: Tensor) -> Tensor:                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 355 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._forward_impl(x)                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 356 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 357 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 358 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_efficientnet\u001b[0m(                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torchvision/models/\u001b[0m\u001b[1;33meffici\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33mentnet.py\u001b[0m:\u001b[94m345\u001b[0m in \u001b[92m_forward_impl\u001b[0m                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 342 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mnn.init.zeros_(m.bias)                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 343 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 344 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_forward_impl\u001b[0m(\u001b[96mself\u001b[0m, x: Tensor) -> Tensor:                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 345 \u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.features(x)                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 346 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 347 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.avgpool(x)                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 348 \u001b[0m\u001b[2m│   │   \u001b[0mx = torch.flatten(x, \u001b[94m1\u001b[0m)                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.p\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mcontaine\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33mr.py\u001b[0m:\u001b[94m139\u001b[0m in \u001b[92mforward\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# with Any as TorchScript expects a more precise type\u001b[0m                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m):                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m:                                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m139 \u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m = module(\u001b[96minput\u001b[0m)                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96minput\u001b[0m                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mappend\u001b[0m(\u001b[96mself\u001b[0m, module: Module) -> \u001b[33m'\u001b[0m\u001b[33mSequential\u001b[0m\u001b[33m'\u001b[0m:                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.p\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mcontaine\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33mr.py\u001b[0m:\u001b[94m139\u001b[0m in \u001b[92mforward\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# with Any as TorchScript expects a more precise type\u001b[0m                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m):                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m:                                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m139 \u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m = module(\u001b[96minput\u001b[0m)                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96minput\u001b[0m                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mappend\u001b[0m(\u001b[96mself\u001b[0m, module: Module) -> \u001b[33m'\u001b[0m\u001b[33mSequential\u001b[0m\u001b[33m'\u001b[0m:                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.p\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torchvision/models/\u001b[0m\u001b[1;33meffici\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33mentnet.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mforward\u001b[0m                                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 162 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.out_channels = cnf.out_channels                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 163 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 164 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 165 \u001b[2m│   │   \u001b[0mresult = \u001b[96mself\u001b[0m.block(\u001b[96minput\u001b[0m)                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.use_res_connect:                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 167 \u001b[0m\u001b[2m│   │   │   \u001b[0mresult = \u001b[96mself\u001b[0m.stochastic_depth(result)                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 168 \u001b[0m\u001b[2m│   │   │   \u001b[0mresult += \u001b[96minput\u001b[0m                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.p\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mcontaine\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33mr.py\u001b[0m:\u001b[94m139\u001b[0m in \u001b[92mforward\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# with Any as TorchScript expects a more precise type\u001b[0m                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m):                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m:                                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m139 \u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m = module(\u001b[96minput\u001b[0m)                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96minput\u001b[0m                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mappend\u001b[0m(\u001b[96mself\u001b[0m, module: Module) -> \u001b[33m'\u001b[0m\u001b[33mSequential\u001b[0m\u001b[33m'\u001b[0m:                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.p\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mcontaine\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33mr.py\u001b[0m:\u001b[94m139\u001b[0m in \u001b[92mforward\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# with Any as TorchScript expects a more precise type\u001b[0m                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m):                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m:                                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m139 \u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m = module(\u001b[96minput\u001b[0m)                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96minput\u001b[0m                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mappend\u001b[0m(\u001b[96mself\u001b[0m, module: Module) -> \u001b[33m'\u001b[0m\u001b[33mSequential\u001b[0m\u001b[33m'\u001b[0m:                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.p\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mbatchnor\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33mm.py\u001b[0m:\u001b[94m179\u001b[0m in \u001b[92mforward\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m176 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.bias,                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   │   \u001b[0mbn_training,                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   │   \u001b[0mexponential_average_factor,                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m179 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.eps,                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m180 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m181 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m182 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m24\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[94m39\u001b[0m in \u001b[92mbatch_norm\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2436 \u001b[0m\u001b[2m│   │   \u001b[0m_verify_batch_size(\u001b[96minput\u001b[0m.size())                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2437 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2438 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch.batch_norm(                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2439 \u001b[2m│   │   \u001b[0m\u001b[96minput\u001b[0m, weight, bias, running_mean, running_var, training, momentum, eps, torch.b  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2440 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2441 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2442 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["model_config = {}\n","\n","model = CNNDetector(model_config).to(device)\n","\n","train_config = {\n","    \"batch_size\": 32,\n","    \"num_epochs\": 5,\n","    \"lr\": 1e-3,\n","    \"valid_folds\":5,\n","    \"save_model\": True,\n","    \"workers\": 1,\n","    \"verbose_step\": 100,\n","    \"weight_decay\": 1e-4,\n","    \"valid_folds\": 5,\n","}\n","\n","valid_config = {\n","    \"batch_size\": 16,\n","    \"workers\": 1,\n","    \"valid_step\": 500\n","}\n","\n","lr = train_config.get(\"lr\", 1e-3)\n","weight_decay = train_config.get(\"weight_decay\", 0.)\n","model_name = \"efficientnetb0\"\n","num_epochs = train_config.get(\"num_epochs\", 1)\n","folds = train_config.get(\"valid_folds\", 5)\n","train_batch_size = train_config.get(\"batch_size\", 32)\n","\n","\n","logger = TensorBoardLogger(f\"logs/{model_name}\", name=model_name)\n","\n","optimiser = torch.optim.Adam(\n","model.parameters(),\n","lr=lr,\n","weight_decay=weight_decay\n",")\n","\n","lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","    optimiser,\n","    max_lr=lr,\n","    epochs=num_epochs,\n","    steps_per_epoch=int((folds-1)/folds*train_df.shape[0]/train_batch_size)+10\n",")\n","\n","torch.cuda.empty_cache()\n","\n","train(model=model,\n","      train_config=train_config,\n","      valid_config=valid_config,\n","      model_name=model_name,\n","      optimiser=optimiser,\n","      lr_scheduler=lr_scheduler,\n","      logger=logger)\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":4}
