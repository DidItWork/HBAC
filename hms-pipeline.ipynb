{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Training Pipeline\n","\n","All dataloading and training in one place!"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-14T05:18:43.921801Z","iopub.status.busy":"2024-04-14T05:18:43.921227Z","iopub.status.idle":"2024-04-14T05:18:52.582521Z","shell.execute_reply":"2024-04-14T05:18:52.581567Z","shell.execute_reply.started":"2024-04-14T05:18:43.921765Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from sklearn.model_selection import KFold, GroupKFold, train_test_split\n","from datetime import datetime\n","from tqdm.notebook import tqdm\n","import albumentations as A\n","import matplotlib.pyplot as plt\n","import os\n","from typing import List, Tuple, Union\n","import pickle\n","from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n","from torcheval.metrics import MulticlassAccuracy\n","from torcheval.metrics.functional import multiclass_f1_score\n","\n","#Local packages\n","from src import CNNDetector, ContrastiveDetector\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\"\"\"\n","Configure\n","\n","Change the paths of the data directory to the location of your HMS Dataset.\n","The sub directories of TRAIN/TEST_EEG, TRAIN/TEST_SPEC should remain the same\n","\n","\"\"\"\n","\n","#Kaggle\n","# DATA_ROOT = \"/kaggle/input/hms-harmful-brain-activity-classification/\"\n","# TRAIN_EEG = \"train_eegs\"\n","# TRAIN_SPEC = \"train_spectrograms\"\n","# TEST_EEG = \"test_eegs\"\n","# TEST_SPEC = \"test_spectrograms\"\n","\n","#Local\n","DATA_ROOT = \"/home/benluo/HBAC/data/hbac\"\n","TRAIN_EEG = \"train_eegs\"\n","TRAIN_SPEC = \"train_spectrograms\"\n","TEST_EEG = \"test_eegs\"\n","TEST_SPEC = \"test_spectrograms\"\n","\n","#Other hyperparams\n","VALID_FOLDS = 5"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:18:52.584370Z","iopub.status.busy":"2024-04-14T05:18:52.583950Z","iopub.status.idle":"2024-04-14T05:18:52.616226Z","shell.execute_reply":"2024-04-14T05:18:52.615329Z","shell.execute_reply.started":"2024-04-14T05:18:52.584344Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Reduce train dataset size\n","\n","The code below only takes the first portion of data in the training list to reduce the number of spectrogram and EEG samples in the training dataset\n","\n","You can choose not to run the following cell if `train_reduced.csv` already exists"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train_reduced.csv already exists\n"]}],"source":["#Get reduced train list as the entire dataset is heavy on RAM, \n","\n","reduce_train_path = os.path.join(DATA_ROOT, \"train_reduced.csv\")\n","\n","if os.path.isfile(reduce_train_path):\n","\n","    print(\"train_reduced.csv already exists\")\n","\n","else:\n","\n","    train_list = pd.read_csv(os.path.join(DATA_ROOT, \"train.csv\"))\n","\n","    reduced_len = train_list.shape[0]//2 #32 GB of RAM during training\n","    # reduced_len = train_list.shape[0]//4 #Less RAM but less data\n","\n","    train_list_reduced = train_list.iloc[:reduced_len,:]\n","\n","    train_list_reduced.to_csv(os.path.join(DATA_ROOT, \"train_reduced.csv\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Generate Data\n","\n","Since test data does not come with labels, for local training and testing, we will only use the data from `train.csv`\n","\n","The Dataset follows a train-val-test split.\n","\n","The train and test datasets are split first by `test_size`.\n","\n","The train and validation datasets are split by Group K-Folds into `val_folds` uniform groups. One group will be chosen randomly for validation while the rest will be used for training every epoch."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def generate_data(val_folds:int = VALID_FOLDS,\n","                  test_size:float = 0.1,\n","                  saved_spec:str = \"all_spec.pkl\",\n","                  saved_eeg:str = \"all_eeg.pkl\"):\n","\n","    #Use reduced csv file\n","    train_list = pd.read_csv(os.path.join(DATA_ROOT, \"train_reduced.csv\"))\n","\n","    print(\"All data\", train_list.shape)\n","    display(train_list.head())\n","\n","    label_cols = train_list.columns[-6:]\n","\n","    #Create new df to be formated for training and testing\n","    train_df = train_list[['spectrogram_id','eeg_id','patient_id','spectrogram_label_offset_seconds','eeg_label_offset_seconds']]\n","\n","    #Normalise labels into probabilities\n","    aux = train_list[label_cols].copy()\n","    \n","    for label in label_cols:\n","        train_df[label] = aux[label].values\n","        \n","    y_data = train_df[label_cols].values\n","    y_data = y_data / y_data.sum(axis=1,keepdims=True)\n","    train_df[label_cols] = y_data\n","\n","    #Target label/class\n","    aux = train_list['expert_consensus'].copy()\n","    train_df['target'] = aux\n","    train_df = train_df.reset_index()\n","\n","    #Sort df by patient id so testing and training data will be less similar\n","    train_df = train_df.sort_values(\"patient_id\")\n","\n","    test_df = train_df.iloc[int((1-test_size)*train_df.shape[0]):]\n","\n","    train_df = train_df.iloc[:int((1-test_size)*train_df.shape[0])]\n","\n","    train_df = train_df.reset_index()\n","    test_df = test_df.reset_index()\n","\n","    print(\"Training data\")\n","    display(train_df.head())\n","\n","    print(\"Testing data\")\n","    display(test_df.head())\n","\n","\n","    gkf = GroupKFold(n_splits=val_folds)\n","\n","    #KFold grouped by patient id\n","    for fold, (train_index, val_index) in enumerate(gkf.split(train_df, train_df.target, train_df.patient_id)):\n","        train_df.loc[val_index, \"fold\"] = int(fold)\n","    \n","    all_eeg = {}\n","    \n","    all_spec = {}\n","\n","    #Try loading eeg and spec data if they have been generated previously\n","    #If not, read eeg and spec data from train_list and save the collection in data folder\n","    #Data is saved as float16 due to space constraints\n","    try:\n","\n","        with open(os.path.join(DATA_ROOT,saved_spec), \"rb\") as handle:\n","            all_spec = pickle.load(handle)\n","\n","        with open(os.path.join(DATA_ROOT,saved_eeg), \"rb\") as handle:\n","            all_eeg = pickle.load(handle)\n","\n","    except:\n","    \n","        for idx, row in tqdm(train_list.iterrows()):\n","\n","            spec_id = row[\"spectrogram_id\"]\n","            eeg_id = row[\"eeg_id\"]\n","\n","            if spec_id not in all_spec:\n","\n","                spec = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_SPEC, str(spec_id)+\".parquet\"))\n","\n","                all_spec[spec_id] = spec.iloc[:,1:].values.astype(dtype=np.float32)\n","\n","            if eeg_id not in all_eeg:\n","\n","                eeg = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_EEG, str(eeg_id)+\".parquet\"))\n","\n","                all_eeg[eeg_id] = eeg.iloc[:,1:].values.astype(dtype=np.float32)\n","        \n","        with open(os.path.join(DATA_ROOT, saved_eeg), \"wb\") as handle:\n","            pickle.dump(all_eeg, handle)\n","        \n","        with open(os.path.join(DATA_ROOT, saved_spec), \"wb\") as handle:\n","            pickle.dump(all_spec, handle)\n","    \n","    return train_df, test_df, all_eeg, all_spec, label_cols"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All data (53400, 16)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>eeg_id</th>\n","      <th>eeg_sub_id</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>spectrogram_id</th>\n","      <th>spectrogram_sub_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>label_id</th>\n","      <th>patient_id</th>\n","      <th>expert_consensus</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1628180742</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>353733</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>127492639</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1628180742</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>353733</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>3887563113</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1628180742</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>353733</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>1142670488</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1628180742</td>\n","      <td>3</td>\n","      <td>18.0</td>\n","      <td>353733</td>\n","      <td>3</td>\n","      <td>18.0</td>\n","      <td>2718991173</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1628180742</td>\n","      <td>4</td>\n","      <td>24.0</td>\n","      <td>353733</td>\n","      <td>4</td>\n","      <td>24.0</td>\n","      <td>3080632009</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0      eeg_id  eeg_sub_id  eeg_label_offset_seconds  \\\n","0           0  1628180742           0                       0.0   \n","1           1  1628180742           1                       6.0   \n","2           2  1628180742           2                       8.0   \n","3           3  1628180742           3                      18.0   \n","4           4  1628180742           4                      24.0   \n","\n","   spectrogram_id  spectrogram_sub_id  spectrogram_label_offset_seconds  \\\n","0          353733                   0                               0.0   \n","1          353733                   1                               6.0   \n","2          353733                   2                               8.0   \n","3          353733                   3                              18.0   \n","4          353733                   4                              24.0   \n","\n","     label_id  patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  \\\n","0   127492639       42516          Seizure             3         0         0   \n","1  3887563113       42516          Seizure             3         0         0   \n","2  1142670488       42516          Seizure             3         0         0   \n","3  2718991173       42516          Seizure             3         0         0   \n","4  3080632009       42516          Seizure             3         0         0   \n","\n","   lrda_vote  grda_vote  other_vote  \n","0          0          0           0  \n","1          0          0           0  \n","2          0          0           0  \n","3          0          0           0  \n","4          0          0           0  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training data\n"]},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self[col] = igetitem(value, i)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>level_0</th>\n","      <th>index</th>\n","      <th>spectrogram_id</th>\n","      <th>eeg_id</th>\n","      <th>patient_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>41744</td>\n","      <td>41744</td>\n","      <td>802850878</td>\n","      <td>1873660287</td>\n","      <td>56</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>49045</td>\n","      <td>49045</td>\n","      <td>957002006</td>\n","      <td>165634434</td>\n","      <td>56</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41746</td>\n","      <td>41746</td>\n","      <td>802850878</td>\n","      <td>2057577408</td>\n","      <td>56</td>\n","      <td>290.0</td>\n","      <td>46.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>41745</td>\n","      <td>41745</td>\n","      <td>802850878</td>\n","      <td>2057577408</td>\n","      <td>56</td>\n","      <td>244.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>25278</td>\n","      <td>25278</td>\n","      <td>497667405</td>\n","      <td>374550767</td>\n","      <td>56</td>\n","      <td>694.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   level_0  index  spectrogram_id      eeg_id  patient_id  \\\n","0    41744  41744       802850878  1873660287          56   \n","1    49045  49045       957002006   165634434          56   \n","2    41746  41746       802850878  2057577408          56   \n","3    41745  41745       802850878  2057577408          56   \n","4    25278  25278       497667405   374550767          56   \n","\n","   spectrogram_label_offset_seconds  eeg_label_offset_seconds  seizure_vote  \\\n","0                               0.0                       0.0           0.0   \n","1                               0.0                       0.0           0.0   \n","2                             290.0                      46.0           0.0   \n","3                             244.0                       0.0           0.0   \n","4                             694.0                       0.0           0.0   \n","\n","   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote target  \n","0       0.0       0.0        0.0        0.0         1.0  Other  \n","1       0.0       0.0        0.0        0.0         1.0  Other  \n","2       0.0       0.0        0.0        0.0         1.0  Other  \n","3       0.0       0.0        0.0        0.0         1.0  Other  \n","4       0.0       0.0        0.0        0.0         1.0  Other  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Testing data\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>level_0</th>\n","      <th>index</th>\n","      <th>spectrogram_id</th>\n","      <th>eeg_id</th>\n","      <th>patient_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5410</td>\n","      <td>5410</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>122.0</td>\n","      <td>122.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5389</td>\n","      <td>5389</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>72.0</td>\n","      <td>72.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5384</td>\n","      <td>5384</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>60.0</td>\n","      <td>60.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5394</td>\n","      <td>5394</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>82.0</td>\n","      <td>82.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5385</td>\n","      <td>5385</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>62.0</td>\n","      <td>62.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   level_0  index  spectrogram_id      eeg_id  patient_id  \\\n","0     5410   5410        91996359  3686473557       57272   \n","1     5389   5389        91996359  3686473557       57272   \n","2     5384   5384        91996359  3686473557       57272   \n","3     5394   5394        91996359  3686473557       57272   \n","4     5385   5385        91996359  3686473557       57272   \n","\n","   spectrogram_label_offset_seconds  eeg_label_offset_seconds  seizure_vote  \\\n","0                             122.0                     122.0           0.0   \n","1                              72.0                      72.0           0.0   \n","2                              60.0                      60.0           0.0   \n","3                              82.0                      82.0           0.0   \n","4                              62.0                      62.0           0.0   \n","\n","   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote target  \n","0       0.0       0.0        1.0        0.0         0.0   LRDA  \n","1       0.0       0.0        1.0        0.0         0.0   LRDA  \n","2       0.0       0.0        1.0        0.0         0.0   LRDA  \n","3       0.0       0.0        1.0        0.0         0.0   LRDA  \n","4       0.0       0.0        1.0        0.0         0.0   LRDA  "]},"metadata":{},"output_type":"display_data"}],"source":["train_df, test_df, all_eeg, all_spec, label_cols = generate_data()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:37:19.304302Z","iopub.status.busy":"2024-04-14T05:37:19.303853Z","iopub.status.idle":"2024-04-14T05:37:19.335251Z","shell.execute_reply":"2024-04-14T05:37:19.334018Z","shell.execute_reply.started":"2024-04-14T05:37:19.304270Z"},"trusted":true},"outputs":[],"source":["class HMSDataset(Dataset):\n","\n","    def __init__(self,\n","                 df:pd.DataFrame = None,\n","                 aug: bool = False) -> None:\n","        \n","\n","        super(HMSDataset, self).__init__()\n","\n","        self.df = df\n","\n","        self.eeg_sample_freq = 200 # 200 Hz\n","        self.spec_sample_freq = 0.5 # 0.5 Hz\n","    \n","        \n","        #data augmentation\n","        self.aug = aug\n","        self.transforms = A.Compose([\n","            A.HorizontalFlip(p=0.5)\n","        ])\n","\n","    def format_data(self, eeg:np.array, spec:np.array) -> Tuple[torch.tensor]:\n","\n","        #Epsilon for numerical stability during division (prevent division by zero)\n","        eps = 1e-6\n","\n","        #Convert data from saved float16 to float32 during training and testing\n","        eeg = eeg.astype(dtype=np.float32)\n","        spec = spec.astype(dtype=np.float32)\n","\n","        #Normalising and getting rid of Nans\n","        eeg_mean = np.nanmean(eeg.flatten())\n","        eeg_std = np.nanstd(eeg.flatten())\n","        eeg = (eeg-eeg_mean)/(eeg_std+eps)\n","        eeg = np.nan_to_num(eeg, nan=0.0)\n","\n","        #Limiting range of spec data\n","        spec = np.clip(spec, np.exp(-4), np.exp(8))\n","        spec = np.log(spec)\n","        \n","        #Normalising and getting rid of Nans\n","        spec_mean = np.nanmean(spec.flatten())\n","        spec_std = np.nanstd(spec.flatten())\n","        spec = (spec-spec_mean)/(spec_std+eps)\n","        spec = np.nan_to_num(spec, nan=0.0)\n","        \n","        #If data augmentation\n","        if self.aug:\n","\n","            eeg = self.transforms(image=eeg)[\"image\"]\n","            spec = self.transforms(image=spec)[\"image\"]\n","\n","        #Convert to tensors\n","        eeg = torch.tensor(eeg.copy())\n","        spec = torch.tensor(spec.copy())\n","\n","        return eeg, spec\n","\n","\n","    def __getitem__(self, index) -> dict:\n","    \n","        row = self.df.iloc[index]\n","\n","        eeg_id = row[\"eeg_id\"]\n","        spec_id = row[\"spectrogram_id\"]\n","\n","        #EEG Sub-sampling\n","        start = int(row[\"eeg_label_offset_seconds\"]*self.eeg_sample_freq)\n","        end = int((row[\"eeg_label_offset_seconds\"]+50)*self.eeg_sample_freq)\n","        eeg = all_eeg[eeg_id][start:end].T\n","        \n","        #Spectrogram Sub-sampling\n","        start = int(row[\"spectrogram_label_offset_seconds\"]*self.spec_sample_freq)\n","        end = int((row[\"spectrogram_label_offset_seconds\"]+600)*self.spec_sample_freq)\n","        spec = all_spec[spec_id][start:end].T\n","\n","        #Normalizing and getting rid of Nans\n","        eeg, spec = self.format_data(eeg, spec)\n","\n","        #Convert label to tensor\n","        label = torch.tensor(row[label_cols], dtype=torch.float32)\n","\n","        return eeg, spec, label\n","\n","\n","    def __len__(self):\n","\n","        return self.df.shape[0]\n","\n","    @staticmethod\n","    def collate_fn(batch):\n","\n","        eeg, spec, label = zip(*batch)\n","        \n","        if eeg is not None:\n","            eeg = torch.stack(eeg, dim=0).float()\n","        \n","        if spec is not None:\n","            spec = torch.stack(spec, dim=0).float().unsqueeze(1).expand(-1,3,-1,-1)\n","\n","        if label is not None:            \n","            label = torch.stack(label, dim=0)\n","        \n","        return {\n","            \"eeg\": eeg,\n","            \"spec\": spec,\n","            \"label\": label\n","        }\n","    "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[torch.Size([19, 10000]), torch.Size([400, 300]), torch.Size([6])]\n","(tensor([[-0.6578, -0.6246, -0.6043,  ...,  2.1034,  1.9578,  2.1060],\n","        [-0.9152, -0.8733, -0.8920,  ...,  1.6163,  1.5519,  1.6318],\n","        [-0.5338, -0.5083, -0.5434,  ...,  1.8302,  1.7877,  1.8650],\n","        ...,\n","        [-0.4207, -0.4307, -0.5225,  ...,  1.9346,  1.9449,  1.9719],\n","        [-0.8559, -0.8398, -0.8708,  ...,  1.6549,  1.6356,  1.6743],\n","        [-0.1548, -0.1980, -0.2424,  ..., -0.2740, -0.3445, -0.3278]]), tensor([[ 1.4396,  1.1608,  1.2323,  ...,  0.6481,  0.6606,  0.6204],\n","        [ 1.5873,  1.3349,  1.2715,  ...,  0.9713,  0.7645,  0.8367],\n","        [ 1.6126,  1.3039,  1.3442,  ...,  1.1260,  1.1426,  1.0092],\n","        ...,\n","        [-1.9244, -2.1493, -2.1493,  ..., -0.0883, -0.2433,  0.1278],\n","        [-1.7645, -1.9244, -2.1493,  ..., -0.1020, -0.2085,  0.1044],\n","        [-1.7645, -1.9244, -2.1493,  ...,  0.1233, -0.2525,  0.3166]]), tensor([0., 0., 0., 1., 0., 0.]))\n"]}],"source":["#Check dataset object is working\n","\n","test_dataset = HMSDataset(df=test_df)\n","\n","print([data.shape for data in test_dataset[0]])\n","\n","print(test_dataset[0])"]},{"cell_type":"markdown","metadata":{},"source":["### Model\n","\n","Load your model here, the current models are supported:\n","\n","1. CNN\n","    - ConvNext\n","    - EfficientNet b0\n","    - EfficientNet v2s\n","2. Custom Architecture\n","    - Contrastive Detector"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ContrastiveDetector(\n","  (kl_loss): KLDivLoss()\n","  (backbone_eeg): Sequential(\n","    (0): Conv1d(19, 64, kernel_size=(5,), stride=(5,), bias=False)\n","    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Conv1d(64, 128, kernel_size=(7,), stride=(5,), bias=False)\n","    (4): Sequential(\n","      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): ReLU()\n","      (2): Conv1d(128, 128, kernel_size=(5,), stride=(3,), bias=False)\n","    )\n","    (5): Sequential(\n","      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): ReLU()\n","      (2): Conv1d(128, 128, kernel_size=(5,), stride=(3,), bias=False)\n","    )\n","    (6): Sequential(\n","      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): ReLU()\n","      (2): Conv1d(128, 128, kernel_size=(5,), stride=(3,), bias=False)\n","    )\n","    (7): Sequential(\n","      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): ReLU()\n","      (2): Conv1d(128, 256, kernel_size=(5,), stride=(3,), bias=False)\n","    )\n","    (8): Sequential(\n","      (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): ReLU()\n","      (2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), bias=False)\n","    )\n","  )\n","  (backbone_spec): EfficientNet(\n","    (features): Sequential(\n","      (0): Conv2dNormActivation(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU(inplace=True)\n","      )\n","      (1): Sequential(\n","        (0): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (2): Conv2dNormActivation(\n","              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n","        )\n","      )\n","      (2): Sequential(\n","        (0): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n","        )\n","        (1): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n","        )\n","      )\n","      (3): Sequential(\n","        (0): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n","              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n","        )\n","        (1): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n","        )\n","      )\n","      (4): Sequential(\n","        (0): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n","        )\n","        (1): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n","        )\n","        (2): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n","        )\n","      )\n","      (5): Sequential(\n","        (0): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n","        )\n","        (1): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n","        )\n","        (2): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n","        )\n","      )\n","      (6): Sequential(\n","        (0): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n","        )\n","        (1): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n","        )\n","        (2): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n","        )\n","        (3): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n","        )\n","      )\n","      (7): Sequential(\n","        (0): MBConv(\n","          (block): Sequential(\n","            (0): Conv2dNormActivation(\n","              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (1): Conv2dNormActivation(\n","              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): SiLU(inplace=True)\n","            )\n","            (2): SqueezeExcitation(\n","              (avgpool): AdaptiveAvgPool2d(output_size=1)\n","              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","              (activation): SiLU(inplace=True)\n","              (scale_activation): Sigmoid()\n","            )\n","            (3): Conv2dNormActivation(\n","              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n","        )\n","      )\n","      (8): Conv2dNormActivation(\n","        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): SiLU(inplace=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=1)\n","    (classifier): Sequential(\n","      (0): Dropout(p=0.2, inplace=True)\n","      (1): Linear(in_features=1280, out_features=512, bias=True)\n","    )\n","  )\n","  (norm_eeg): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (norm_spec): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (head): Sequential(\n","    (0): Linear(in_features=1024, out_features=256, bias=False)\n","    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=256, out_features=6, bias=False)\n","  )\n","  (output_layer): Softmax(dim=1)\n",")\n"]}],"source":["model_config = {\n","    \"model_name\": \"efficientnet_b0\",\n","    \"num_features\": 512,\n","    \"num_classes\": 6,\n","}\n","\n","# model = CNNDetector(model_config).to(device)\n","model = ContrastiveDetector(model_config).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Training and Testing\n","\n","Validation is done every `test_step` to check if model is overfitting on training data.\n","\n","Testing is done at the end of every epoch with the model produced by that epoch.\n","\n","Training and testing metrics can be viewed in tensorboard as mentioned in the README."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T02:39:35.310349Z","iopub.status.busy":"2024-04-14T02:39:35.309988Z","iopub.status.idle":"2024-04-14T02:39:35.324053Z","shell.execute_reply":"2024-04-14T02:39:35.322936Z","shell.execute_reply.started":"2024-04-14T02:39:35.310321Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def validate(model, valid_dataloader):\n","\n","    model.eval()\n","\n","    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n","\n","    loss = torch.tensor([0.]).to(device)\n","\n","    for batch in tqdm(valid_dataloader):\n","\n","        for key in batch:\n","\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","        \n","        predictions = F.log_softmax(predictions,dim=1)\n","\n","        loss += loss_fn(predictions,batch[\"label\"])\n","\n","    loss = loss / len(valid_dataloader)\n","\n","    model.train()\n","\n","    print(\"Validation loss\", loss.item())\n","\n","    return loss.item()\n","\n","@torch.no_grad()\n","def test(model, test_dataloader):\n","\n","    model.eval()\n","\n","    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n","\n","    num_classes = 6\n","\n","    acc = MulticlassAccuracy(average=\"macro\", num_classes=num_classes)\n","    f1_score = torch.tensor([0.]).to(device)\n","    loss = torch.tensor([0.]).to(device)\n","     \n","    for batch in tqdm(test_dataloader):\n","\n","        for key in batch:\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","\n","        loss += loss_fn(F.log_softmax(predictions, dim=1), batch[\"label\"])\n","\n","        predictions = F.softmax(predictions, dim=1)\n","\n","        predictions = torch.argmax(predictions, dim=1)\n","\n","        classes = torch.argmax(batch[\"label\"], dim=1)\n","\n","        f1_score += multiclass_f1_score(predictions, classes, num_classes=num_classes)\n","\n","        acc.update(predictions, classes)\n","\n","    model.train()\n","\n","    f1_score /= len(test_dataloader)\n","    loss /= len(test_dataloader)\n","\n","    return acc.compute(), f1_score, loss\n","\n","#training\n","\n","def train_epoch(model=None,\n","          train_dataloader=None,\n","          valid_dataloader=None,\n","          test_dataloader=None,\n","          optimiser = None,\n","          train_config=None,\n","          valid_config=None,\n","          lr_scheduler=None,\n","          min_valid_loss=100.,\n","          min_test_loss=100.,\n","          model_name=\"model\",\n","          epoch=0,\n","          logger=None):\n","    \n","    \"\"\"\n","    Training Function\n","    \"\"\"\n","\n","    assert(train_dataloader is not None)\n","    \n","    assert(model is not None)\n","\n","    #Training Params\n","\n","    save_model = train_config.get(\"save_model\", True)\n","    to_model_keys = [\"spec\", \"eeg\", \"label\"]\n","    valid_step = valid_config.get(\"valid_step\", 1000)\n","    verbose_step = train_config.get(\"verbose_step\", 10)\n","    \n","    \n","    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n","    \n","    model.train()\n","    \n","    for itr, batch in tqdm(enumerate(train_dataloader)):\n","\n","#       print(batch[\"eeg\"].shape)\n","\n","        #Train One Iteration\n","\n","        #Load data to GPU\n","\n","        for key in to_model_keys:\n","\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","\n","        if \"contrastive\" in model_name:\n","\n","            klloss, contrastive_loss = model.get_loss(predictions, batch[\"label\"])\n","\n","            loss = klloss+contrastive_loss\n","        \n","        else:\n","            \n","            loss = model.get_loss(predictions,batch[\"label\"])\n","        \n","        optimiser.zero_grad()\n","\n","        loss.backward()\n","\n","        optimiser.step()\n","        \n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","        \n","        if itr%verbose_step==0:\n","            print(f\"Training itr {itr}/{len(train_dataloader)}\")\n","            for param_group in optimiser.param_groups:\n","                lr = param_group['lr']\n","                break\n","            \n","\n","            if \"contrastive\" in model_name:\n","                print(\"Training KL Loss: \", klloss.item(), \"Training Contrastive Loss: \", contrastive_loss.item(), \"Learning Rate:\", lr)\n","                logger.log_metrics({\"train/klloss\":klloss, \"train/contrastiveloss\": contrastive_loss, \"train/lr\": lr}, itr+epoch*len(train_dataloader))\n","            else:\n","                print(\"Training Loss: \", loss.item(), \"Learning Rate:\", lr)\n","                logger.log_metrics({\"train/loss\":loss, \"train/lr\": lr}, itr+epoch*len(train_dataloader))\n","        \n","        #Validation\n","        \n","        if itr%valid_step==0 and itr>0 and valid_dataloader is not None:\n","            print(\"Validation\")\n","            valid_loss = validate(model, valid_dataloader)\n","            \n","            if valid_loss < min_valid_loss and save_model:\n","                min_valid_loss = valid_loss\n","                save_path = os.path.join(DATA_ROOT,\"models\")\n","                os.makedirs(save_path, exist_ok=True)\n","                torch.save(model.state_dict(), os.path.join(save_path, f\"{model_name}_best.pt\"))\n","            logger.log_metrics({\"valid/loss\":valid_loss}, itr+epoch*len(train_dataloader))\n","        \n","    #Test\n","    if test_dataloader is not None:\n","        acc, f1_score, loss = test(model, test_dataloader)\n","        if loss < min_test_loss:\n","            min_test_loss = loss\n","        logger.log_metrics({\"test/acc\":acc, \"test/f1_score\":f1_score, \"test/loss\":loss}, itr+epoch*len(train_dataloader))\n","    return min_valid_loss, min_test_loss"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def train(model=None,\n","          optimiser=None,\n","          lr_scheduler=None,\n","          train_config=None,\n","          valid_config=None,\n","          test_dataloader=None,\n","          model_name=\"model\",\n","          logger=None):\n","    \n","    train_batch_size = train_config.get(\"batch_size\", 32)\n","    num_epochs = train_config.get(\"num_epochs\", 10)\n","    valid_folds = train_config.get(\"valid_folds\", 5)\n","    valid_batch_size = valid_config.get(\"batch_size\", 32)\n","    train_workers = train_config.get(\"workers\", 1)\n","    valid_workers = valid_config.get(\"workers\", 1)\n","\n","    min_valid_loss = 100.\n","    min_test_loss = 100.\n","\n","    for epoch in range(num_epochs):\n","\n","        print(\"Epoch\", epoch)\n","\n","        #KGFolds\n","        fold = np.random.randint(valid_folds)\n","        train_df_fold = train_df[train_df[\"fold\"]!=fold]\n","        valid_df = train_df[train_df[\"fold\"]==fold]\n","        train_dataset = HMSDataset(train_df_fold, aug=True)\n","        valid_dataset = HMSDataset(valid_df, aug=False)\n","\n","        train_dataloader = DataLoader(\n","            dataset=train_dataset,\n","            batch_size = train_batch_size,\n","            shuffle=True,\n","            num_workers=train_workers,\n","            collate_fn=train_dataset.collate_fn\n","        )\n","\n","        valid_dataloader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size = valid_batch_size,\n","            shuffle=True,\n","            num_workers=valid_workers,\n","            collate_fn=valid_dataset.collate_fn\n","        )\n","\n","        min_valid_loss, min_test_loss = train_epoch(model=model,\n","                    train_dataloader=train_dataloader,\n","                    valid_dataloader=valid_dataloader,\n","                    test_dataloader=test_dataloader,\n","                    optimiser=optimiser,\n","                    train_config=train_config,\n","                    valid_config=valid_config,\n","                    lr_scheduler=lr_scheduler,\n","                    min_valid_loss=min_valid_loss,\n","                    min_test_loss=min_test_loss,\n","                    model_name=model_name,\n","                    epoch=epoch,\n","                    logger=logger)\n","        print(\"Min Valid Loss\", min_valid_loss, \"Min Test Loss\", min_test_loss)"]},{"cell_type":"markdown","metadata":{},"source":["#### Hyperparameters\n","\n","Configuration of hyperparamters for training and validation/testing is shown below.\n","\n","If you would like to train the contrastive detector, set `model_name` to \"contrastive_{backbone_name}\", e.g. \"contrastive_efficientnetb0\". Otherwise, Set `model_name` to \"cnn_detector_{backbone_name}\".\n","\n","- `batch_size`: size of one mini-batch of data per forward pass of the model during training, validation and testing respectively\n","- `lr`: learning rate, depends on optimiser and learning rate scheduler\n","- `save_model`: saves the best model determined by validation loss\n","- `valid_folds`: set during dataset geneartion, the number of groups to have in Group KFolds training\n","- `verbose_step`: iteration step interval to print and log training metrics\n","- `valid_step`: iteration step interval to perform validation on model and save best model by validation loss\n","- `workers`: number of CPU workers to load dataset for training, validation, and testing. A higher number requires more RAM but may speed up training"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T02:39:35.801324Z","iopub.status.busy":"2024-04-14T02:39:35.800510Z","iopub.status.idle":"2024-04-14T02:56:53.096301Z","shell.execute_reply":"2024-04-14T02:56:53.094732Z","shell.execute_reply.started":"2024-04-14T02:39:35.801292Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ea66e6993cf4d42a3e9dd7fa21c8ff7","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training itr 0/1202\n","Training KL Loss:  1.535893440246582 Training Contrastive Loss:  -0.010634609498083591 Learning Rate: 4.0000718651559374e-05\n"]},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1545: RuntimeWarning: invalid value encountered in subtract\n","  np.subtract(arr, avg, out=arr, casting='unsafe')\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in subtract\n"]},{"name":"stdout","output_type":"stream","text":["Training itr 100/1202\n","Training KL Loss:  0.8607556819915771 Training Contrastive Loss:  0.0014440745580941439 Learning Rate: 4.731232458808946e-05\n","Training itr 200/1202\n","Training KL Loss:  0.6186394095420837 Training Contrastive Loss:  -0.00841532088816166 Learning Rate: 6.874272265430651e-05\n","Training itr 300/1202\n","Training KL Loss:  0.7805444598197937 Training Contrastive Loss:  -0.03355320543050766 Learning Rate: 0.00010365180448417455\n","Training itr 400/1202\n","Training KL Loss:  0.6708669662475586 Training Contrastive Loss:  -0.142753005027771 Learning Rate: 0.00015099686451240733\n","Training itr 500/1202\n","Training KL Loss:  0.486168771982193 Training Contrastive Loss:  -0.269393652677536 Learning Rate: 0.0002093637447321907\n","Validation\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"127f3eebeca043c5ba18a83f315bf8a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/301 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss 0.8027375936508179\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">59</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">59</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_epoch</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">133</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lr_scheduler.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">65</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  62 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>instance = instance_ref()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  63 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>instance._step_count += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  64 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>wrapped = func.<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__get__</span>(instance, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  65 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapped(*args, **kwargs)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  66 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  67 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Note that the returned function here is no longer a bound method,</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  68 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># so attributes like `__func__` and `__self__` no longer exist.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>: <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">109</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>obj, *_ = args                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>profile_name = <span style=\"color: #808000; text-decoration-color: #808000\">\"Optimizer.step#{}.step\"</span>.format(obj.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>)     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.autograd.profiler.record_function(profile_name):                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>109 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hooked = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.step, <span style=\"color: #808000; text-decoration-color: #808000\">\"hooked\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">grad_mode.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">27</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.clone():                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 27 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cast(F, decorate_context)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrap_generator</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, func):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">adam.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">171</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │    </span>eps=group[<span style=\"color: #808000; text-decoration-color: #808000\">'eps'</span>],                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │    </span>maximize=group[<span style=\"color: #808000; text-decoration-color: #808000\">'maximize'</span>],                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │    </span>foreach=group[<span style=\"color: #808000; text-decoration-color: #808000\">'foreach'</span>],                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>171 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │    </span>capturable=group[<span style=\"color: #808000; text-decoration-color: #808000\">'capturable'</span>])                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">adam.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">226</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">adam</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">223 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │    </span>weight_decay=weight_decay,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">224 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │    </span>eps=eps,                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │    </span>maximize=maximize,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>226 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │    </span>capturable=capturable)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">229 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_single_tensor_adam</span>(params: List[Tensor],                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">adam.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">265</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_single_tensor_adam</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">262 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">263 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Decay the first and second moment running average coefficient</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">264 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>exp_avg.mul_(beta1).add_(grad, alpha=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> - beta1)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>265 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> - beta2)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">267 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> capturable:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">268 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>step = step_t                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"],"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m59\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mtrain\u001b[0m:\u001b[94m59\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mtrain_epoch\u001b[0m:\u001b[94m133\u001b[0m                                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/optim/\u001b[0m\u001b[1;33mlr_scheduler.\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m65\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  62 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minstance = instance_ref()                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  63 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minstance._step_count += \u001b[94m1\u001b[0m                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  64 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mwrapped = func.\u001b[92m__get__\u001b[0m(instance, \u001b[96mcls\u001b[0m)                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  65 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m wrapped(*args, **kwargs)                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  66 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  67 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Note that the returned function here is no longer a bound method,\u001b[0m           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m  68 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# so attributes like `__func__` and `__self__` no longer exist.\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m: \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[94m109\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mobj, *_ = args                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mprofile_name = \u001b[33m\"\u001b[0m\u001b[33mOptimizer.step#\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m.step\u001b[0m\u001b[33m\"\u001b[0m.format(obj.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m)     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.autograd.profiler.record_function(profile_name):                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m109 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   \u001b[0mhooked = \u001b[96mgetattr\u001b[0m(\u001b[96mself\u001b[0m.\u001b[91m__class__\u001b[0m.step, \u001b[33m\"\u001b[0m\u001b[33mhooked\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m)                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/autograd/\u001b[0m\u001b[1;33mgrad_mode.\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m27\u001b[0m in \u001b[92mdecorate_context\u001b[0m                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 24 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 25 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 26 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.clone():                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 27 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 28 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cast(F, decorate_context)                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 29 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 30 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_wrap_generator\u001b[0m(\u001b[96mself\u001b[0m, func):                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/optim/\u001b[0m\u001b[1;33madam.py\u001b[0m:\u001b[94m171\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mstep\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   │   │   │    \u001b[0meps=group[\u001b[33m'\u001b[0m\u001b[33meps\u001b[0m\u001b[33m'\u001b[0m],                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   │   │    \u001b[0mmaximize=group[\u001b[33m'\u001b[0m\u001b[33mmaximize\u001b[0m\u001b[33m'\u001b[0m],                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   │   │   │    \u001b[0mforeach=group[\u001b[33m'\u001b[0m\u001b[33mforeach\u001b[0m\u001b[33m'\u001b[0m],                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m171 \u001b[2m│   │   │   │    \u001b[0mcapturable=group[\u001b[33m'\u001b[0m\u001b[33mcapturable\u001b[0m\u001b[33m'\u001b[0m])                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m loss                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/optim/\u001b[0m\u001b[1;33madam.py\u001b[0m:\u001b[94m226\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92madam\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m223 \u001b[0m\u001b[2m│   │    \u001b[0mweight_decay=weight_decay,                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m224 \u001b[0m\u001b[2m│   │    \u001b[0meps=eps,                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2m│   │    \u001b[0mmaximize=maximize,                                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m226 \u001b[2m│   │    \u001b[0mcapturable=capturable)                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m228 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m229 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_single_tensor_adam\u001b[0m(params: List[Tensor],                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/torch/optim/\u001b[0m\u001b[1;33madam.py\u001b[0m:\u001b[94m265\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m_single_tensor_adam\u001b[0m                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m263 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Decay the first and second moment running average coefficient\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2m│   │   \u001b[0mexp_avg.mul_(beta1).add_(grad, alpha=\u001b[94m1\u001b[0m - beta1)                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m265 \u001b[2m│   │   \u001b[0mexp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=\u001b[94m1\u001b[0m - beta2)                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m266 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m267 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m capturable:                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m268 \u001b[0m\u001b[2m│   │   │   \u001b[0mstep = step_t                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["train_config = {\n","    \"batch_size\": 32,\n","    \"num_epochs\": 5,\n","    \"lr\": 1e-3,\n","    \"save_model\": True,\n","    \"workers\": 1,\n","    \"verbose_step\": 100,\n","    \"weight_decay\": 1e-4,\n","    \"valid_folds\": VALID_FOLDS,\n","}\n","\n","valid_config = {\n","    \"batch_size\": 32,\n","    \"workers\": 1,\n","    \"valid_step\": 500\n","}\n","\n","lr = train_config.get(\"lr\", 1e-3)\n","weight_decay = train_config.get(\"weight_decay\", 0.)\n","model_name = \"contrastive\"\n","num_epochs = train_config.get(\"num_epochs\", 1)\n","folds = train_config.get(\"valid_folds\", 5)\n","train_batch_size = train_config.get(\"batch_size\", 32)\n","test_batch_size = valid_config.get(\"batch_size\", 32)\n","\n","\n","logger = TensorBoardLogger(f\"logs/{model_name}\", name=model_name)\n","\n","optimiser = torch.optim.Adam(\n","model.parameters(),\n","lr=lr,\n","weight_decay=weight_decay\n",")\n","\n","lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","    optimiser,\n","    max_lr=lr,\n","    epochs=num_epochs,\n","    steps_per_epoch=int((folds-1)/folds*train_df.shape[0]/train_batch_size)+10\n",")\n","\n","test_dataset = HMSDataset(df=test_df)\n","\n","test_dataloader = DataLoader(\n","    dataset=test_dataset,\n","    batch_size=test_batch_size,\n","    collate_fn=test_dataset.collate_fn\n",")\n","\n","torch.cuda.empty_cache()\n","\n","train(model=model,\n","      train_config=train_config,\n","      valid_config=valid_config,\n","      test_dataloader=test_dataloader,\n","      model_name=model_name,\n","      optimiser=optimiser,\n","      lr_scheduler=lr_scheduler,\n","      logger=logger)\n","\n","    "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
