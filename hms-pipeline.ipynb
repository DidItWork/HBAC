{"cells":[{"cell_type":"code","execution_count":86,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-14T05:18:43.921801Z","iopub.status.busy":"2024-04-14T05:18:43.921227Z","iopub.status.idle":"2024-04-14T05:18:52.582521Z","shell.execute_reply":"2024-04-14T05:18:52.581567Z","shell.execute_reply.started":"2024-04-14T05:18:43.921765Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.models import efficientnet_b0\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from sklearn.model_selection import KFold, GroupKFold, train_test_split\n","from datetime import datetime\n","from tqdm import tqdm\n","import albumentations as A\n","import gc\n","import matplotlib.pyplot as plt\n","import math\n","import multiprocessing\n","import os\n","import time\n","import random\n","from env import *\n","from typing import List, Tuple, Union\n","import pickle\n","from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["#Kaggle\n","# DATA_ROOT = \"/kaggle/input/hms-harmful-brain-activity-classification/\"\n","# TRAIN_EEG = \"train_eegs\"\n","# TRAIN_SPEC = \"train_spectrograms\"\n","# TEST_EEG = \"test_eegs\"\n","# TEST_SPEC = \"test_spectrograms\"\n","\n","#Local\n","DATA_ROOT = \"/home/benluo/HBAC/data/hbac\"\n","TRAIN_EEG = \"train_eegs\"\n","TRAIN_SPEC = \"train_spectrograms\"\n","TEST_EEG = \"test_eegs\"\n","TEST_SPEC = \"test_spectrograms\""]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:18:52.584370Z","iopub.status.busy":"2024-04-14T05:18:52.583950Z","iopub.status.idle":"2024-04-14T05:18:52.616226Z","shell.execute_reply":"2024-04-14T05:18:52.615329Z","shell.execute_reply.started":"2024-04-14T05:18:52.584344Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["train_list = pd.read_csv(os.path.join(DATA_ROOT, \"train.csv\"))\n","\n","train_list_reduced = train_list.iloc[:train_list.shape[0]//2,:]\n","\n","train_list_reduced.to_csv(os.path.join(DATA_ROOT, \"train_reduced.csv\"))"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["def generate_data(val_folds:int = 5,\n","                  test_size:float = 0.2,\n","                  saved_spec:str = \"all_spec.pkl\",\n","                  saved_eeg:str = \"all_eeg.pkl\"):\n","\n","    train_list = pd.read_csv(os.path.join(DATA_ROOT, \"train_reduced.csv\"))\n","\n","    print(\"All data\")\n","    display(train_list.head())\n","\n","    # test_df = pd.read_csv(os.path.join(DATA_ROOT, \"test.csv\"))\n","\n","    label_cols = train_list.columns[-6:]\n","    \n","\n","    #Select first eeg and spectrogram in each spectrogram file\n","    train_df = train_list[['spectrogram_id','eeg_id','patient_id','spectrogram_label_offset_seconds','eeg_label_offset_seconds']]\n","\n","    aux = train_list[label_cols].copy()\n","    \n","    for label in label_cols:\n","        train_df[label] = aux[label].values\n","        \n","    y_data = train_df[label_cols].values\n","    y_data = y_data / y_data.sum(axis=1,keepdims=True)\n","    train_df[label_cols] = y_data\n","\n","    aux = train_list['expert_consensus'].copy()\n","    train_df['target'] = aux\n","    train_df = train_df.reset_index()\n","\n","    train_df = train_df.sort_values(\"patient_id\")\n","\n","    test_df = train_df.iloc[int(0.9*train_df.shape[0]):]\n","\n","    train_df = train_df.iloc[:int(0.9*train_df.shape[0])]\n","\n","    train_df = train_df.reset_index()\n","    test_df = test_df.reset_index()\n","\n","    print(\"Training data\")\n","    display(train_df.head())\n","\n","    print(\"Testing data\")\n","    display(test_df.head())\n","\n","\n","    gkf = GroupKFold(n_splits=val_folds)\n","\n","    #KFold grouped by patient ID\n","    for fold, (train_index, val_index) in enumerate(gkf.split(train_df, train_df.target, train_df.patient_id)):\n","        train_df.loc[val_index, \"fold\"] = int(fold)\n","    \n","    all_eeg = {}\n","    \n","    all_spec = {}\n","\n","\n","    try:\n","\n","        with open(os.path.join(DATA_ROOT,saved_spec), \"rb\") as handle:\n","            all_spec = pickle.load(handle)\n","\n","        with open(os.path.join(DATA_ROOT,saved_eeg), \"rb\") as handle:\n","            all_eeg = pickle.load(handle)\n","\n","    except:\n","    \n","        for idx, row in tqdm(train_list.iterrows()):\n","\n","            spec_id = row[\"spectrogram_id\"]\n","            eeg_id = row[\"eeg_id\"]\n","\n","            if spec_id not in all_spec:\n","\n","                spec = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_SPEC, str(spec_id)+\".parquet\"))\n","\n","                all_spec[spec_id] = spec.iloc[:,1:].values.astype(dtype=np.float16)\n","\n","            if eeg_id not in all_eeg:\n","\n","                eeg = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_EEG, str(eeg_id)+\".parquet\"))\n","\n","                all_eeg[eeg_id] = eeg.iloc[:,1:].values.astype(dtype=np.float16)\n","        \n","        with open(os.path.join(DATA_ROOT, saved_eeg), \"wb\") as handle:\n","            pickle.dump(all_eeg, handle)\n","        \n","        with open(os.path.join(DATA_ROOT, saved_spec), \"wb\") as handle:\n","            pickle.dump(all_spec, handle)\n","    \n","    # for i, row in tqdm(test_df.iterrows()):\n","            \n","    #     eeg_id = row[\"eeg_id\"]\n","    #     spec_id = row[\"spectrogram_id\"]\n","\n","    #     if eeg_id not in test_eeg:\n","\n","    #         eeg = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_EEG, str(eeg_id)+\".parquet\"))\n","\n","\n","    #     if spec_id not in test_spec:\n","    \n","    #         spec = pd.read_parquet(os.path.join(DATA_ROOT, TRAIN_SPEC, str(spec_id)+\".parquet\"))\n","        \n","    #     test_eeg[eeg_id] = eeg.iloc[:,1:].values.astype(dtype=np.float16)\n","    #     test_spec[spec_id] = spec.iloc[:,1:].values.astype(dtype=np.float16)\n","    \n","    return train_df, test_df, all_eeg, all_spec, label_cols"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All data\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>eeg_id</th>\n","      <th>eeg_sub_id</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>spectrogram_id</th>\n","      <th>spectrogram_sub_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>label_id</th>\n","      <th>patient_id</th>\n","      <th>expert_consensus</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1628180742</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>353733</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>127492639</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1628180742</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>353733</td>\n","      <td>1</td>\n","      <td>6.0</td>\n","      <td>3887563113</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1628180742</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>353733</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>1142670488</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1628180742</td>\n","      <td>3</td>\n","      <td>18.0</td>\n","      <td>353733</td>\n","      <td>3</td>\n","      <td>18.0</td>\n","      <td>2718991173</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1628180742</td>\n","      <td>4</td>\n","      <td>24.0</td>\n","      <td>353733</td>\n","      <td>4</td>\n","      <td>24.0</td>\n","      <td>3080632009</td>\n","      <td>42516</td>\n","      <td>Seizure</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0      eeg_id  eeg_sub_id  eeg_label_offset_seconds  \\\n","0           0  1628180742           0                       0.0   \n","1           1  1628180742           1                       6.0   \n","2           2  1628180742           2                       8.0   \n","3           3  1628180742           3                      18.0   \n","4           4  1628180742           4                      24.0   \n","\n","   spectrogram_id  spectrogram_sub_id  spectrogram_label_offset_seconds  \\\n","0          353733                   0                               0.0   \n","1          353733                   1                               6.0   \n","2          353733                   2                               8.0   \n","3          353733                   3                              18.0   \n","4          353733                   4                              24.0   \n","\n","     label_id  patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  \\\n","0   127492639       42516          Seizure             3         0         0   \n","1  3887563113       42516          Seizure             3         0         0   \n","2  1142670488       42516          Seizure             3         0         0   \n","3  2718991173       42516          Seizure             3         0         0   \n","4  3080632009       42516          Seizure             3         0         0   \n","\n","   lrda_vote  grda_vote  other_vote  \n","0          0          0           0  \n","1          0          0           0  \n","2          0          0           0  \n","3          0          0           0  \n","4          0          0           0  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training data\n"]},{"name":"stderr","output_type":"stream","text":["/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self[col] = igetitem(value, i)\n","/home/benluo/miniconda3/envs/DeepfakeBench/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>level_0</th>\n","      <th>index</th>\n","      <th>spectrogram_id</th>\n","      <th>eeg_id</th>\n","      <th>patient_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>41744</td>\n","      <td>41744</td>\n","      <td>802850878</td>\n","      <td>1873660287</td>\n","      <td>56</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>49045</td>\n","      <td>49045</td>\n","      <td>957002006</td>\n","      <td>165634434</td>\n","      <td>56</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41746</td>\n","      <td>41746</td>\n","      <td>802850878</td>\n","      <td>2057577408</td>\n","      <td>56</td>\n","      <td>290.0</td>\n","      <td>46.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>41745</td>\n","      <td>41745</td>\n","      <td>802850878</td>\n","      <td>2057577408</td>\n","      <td>56</td>\n","      <td>244.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>25278</td>\n","      <td>25278</td>\n","      <td>497667405</td>\n","      <td>374550767</td>\n","      <td>56</td>\n","      <td>694.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Other</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   level_0  index  spectrogram_id      eeg_id  patient_id  \\\n","0    41744  41744       802850878  1873660287          56   \n","1    49045  49045       957002006   165634434          56   \n","2    41746  41746       802850878  2057577408          56   \n","3    41745  41745       802850878  2057577408          56   \n","4    25278  25278       497667405   374550767          56   \n","\n","   spectrogram_label_offset_seconds  eeg_label_offset_seconds  seizure_vote  \\\n","0                               0.0                       0.0           0.0   \n","1                               0.0                       0.0           0.0   \n","2                             290.0                      46.0           0.0   \n","3                             244.0                       0.0           0.0   \n","4                             694.0                       0.0           0.0   \n","\n","   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote target  \n","0       0.0       0.0        0.0        0.0         1.0  Other  \n","1       0.0       0.0        0.0        0.0         1.0  Other  \n","2       0.0       0.0        0.0        0.0         1.0  Other  \n","3       0.0       0.0        0.0        0.0         1.0  Other  \n","4       0.0       0.0        0.0        0.0         1.0  Other  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Testing data\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>level_0</th>\n","      <th>index</th>\n","      <th>spectrogram_id</th>\n","      <th>eeg_id</th>\n","      <th>patient_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5410</td>\n","      <td>5410</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>122.0</td>\n","      <td>122.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5389</td>\n","      <td>5389</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>72.0</td>\n","      <td>72.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5384</td>\n","      <td>5384</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>60.0</td>\n","      <td>60.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5394</td>\n","      <td>5394</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>82.0</td>\n","      <td>82.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5385</td>\n","      <td>5385</td>\n","      <td>91996359</td>\n","      <td>3686473557</td>\n","      <td>57272</td>\n","      <td>62.0</td>\n","      <td>62.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>LRDA</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   level_0  index  spectrogram_id      eeg_id  patient_id  \\\n","0     5410   5410        91996359  3686473557       57272   \n","1     5389   5389        91996359  3686473557       57272   \n","2     5384   5384        91996359  3686473557       57272   \n","3     5394   5394        91996359  3686473557       57272   \n","4     5385   5385        91996359  3686473557       57272   \n","\n","   spectrogram_label_offset_seconds  eeg_label_offset_seconds  seizure_vote  \\\n","0                             122.0                     122.0           0.0   \n","1                              72.0                      72.0           0.0   \n","2                              60.0                      60.0           0.0   \n","3                              82.0                      82.0           0.0   \n","4                              62.0                      62.0           0.0   \n","\n","   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote target  \n","0       0.0       0.0        1.0        0.0         0.0   LRDA  \n","1       0.0       0.0        1.0        0.0         0.0   LRDA  \n","2       0.0       0.0        1.0        0.0         0.0   LRDA  \n","3       0.0       0.0        1.0        0.0         0.0   LRDA  \n","4       0.0       0.0        1.0        0.0         0.0   LRDA  "]},"metadata":{},"output_type":"display_data"}],"source":["train_df, test_df, all_eeg, all_spec, label_cols = generate_data()"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:37:19.304302Z","iopub.status.busy":"2024-04-14T05:37:19.303853Z","iopub.status.idle":"2024-04-14T05:37:19.335251Z","shell.execute_reply":"2024-04-14T05:37:19.334018Z","shell.execute_reply.started":"2024-04-14T05:37:19.304270Z"},"trusted":true},"outputs":[],"source":["#data processing\n","class HMSDataset(Dataset):\n","\n","    def __init__(self,\n","                 df:pd.DataFrame = None,\n","                 aug: bool = False) -> None:\n","        \n","\n","        super(HMSDataset, self).__init__()\n","\n","        self.df = df\n","\n","        #Data augmentation\n","        self.aug = aug\n","\n","        self.eeg_sample_freq = 200 # 200 Hz\n","        self.spec_sample_freq = 0.5 # 0.5 Hz\n","    \n","        \n","        #data augmentation\n","        self.transforms = A.Compose([\n","            A.HorizontalFlip(p=0.5)\n","        ])\n","\n","    def format_data(self, eeg:np.array, spec:np.array) -> Tuple[torch.tensor]:\n","\n","        eps = 1e-6\n","\n","        eeg = eeg.astype(dtype=np.float32)\n","        spec = spec.astype(dtype=np.float32)\n","\n","        #Normalizing and getting rid of Nans\n","        eeg_mean = np.nanmean(eeg.flatten())\n","        eeg_std = np.nanstd(eeg.flatten())\n","        eeg = (eeg-eeg_mean)/(eeg_std+eps)\n","        eeg = np.nan_to_num(eeg, nan=0.0)\n","\n","        #Normalizing and getting rid of Nans\n","        spec = np.clip(spec, np.exp(-4), np.exp(8))\n","        spec = np.log(spec)\n","        \n","        spec_mean = np.nanmean(spec.flatten())\n","        spec_std = np.nanstd(spec.flatten())\n","        spec = (spec-spec_mean)/(spec_std+eps)\n","        spec = np.nan_to_num(spec, nan=0.0)\n","        \n","        if self.aug:\n","\n","            eeg = self.transforms(image=eeg)[\"image\"]\n","            spec = self.transforms(image=spec)[\"image\"]\n","\n","        eeg = torch.tensor(eeg.copy())\n","        spec = torch.tensor(spec.copy())\n","\n","        return eeg, spec\n","\n","\n","    def __getitem__(self, index) -> dict:\n","    \n","        row = self.df.iloc[index]\n","\n","        eeg_id = row[\"eeg_id\"]\n","        spec_id = row[\"spectrogram_id\"]\n","\n","        #EEG Sub-sampling\n","        start = int(row[\"eeg_label_offset_seconds\"]*self.eeg_sample_freq)\n","        end = int((row[\"eeg_label_offset_seconds\"]+50)*self.eeg_sample_freq)\n","        eeg = all_eeg[eeg_id][start:end]\n","        \n","        #Spectrogram Sub-sampling\n","        start = int(row[\"spectrogram_label_offset_seconds\"]*self.spec_sample_freq)\n","        end = int((row[\"spectrogram_label_offset_seconds\"]+600)*self.spec_sample_freq)\n","        spec = all_spec[spec_id][start:end]\n","\n","        # print(all_eeg[eeg_id].shape, eeg.shape, all_spec[spec_id].shape, spec.shape)\n","\n","        eeg, spec = self.format_data(eeg, spec)\n","\n","        label = torch.tensor(row[label_cols], dtype=torch.float32)\n","\n","        return eeg, spec, label\n","\n","\n","    def __len__(self):\n","\n","        return self.df.shape[0]\n","\n","    @staticmethod\n","    def collate_fn(batch):\n","\n","        eeg, spec, label = zip(*batch)\n","        \n","        if eeg is not None:\n","            eeg = torch.stack(eeg, dim=0).float().unsqueeze(1)\n","        \n","        if spec is not None:\n","            spec = torch.stack(spec, dim=0).float().unsqueeze(1).expand(-1,3,-1,-1)\n","\n","        if label is not None:            \n","            label = torch.stack(label, dim=0)\n","        \n","        return {\n","            \"eeg\": eeg,\n","            \"spec\": spec,\n","            \"label\": label\n","        }\n","    "]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:27:07.257131Z","iopub.status.busy":"2024-04-14T05:27:07.256459Z","iopub.status.idle":"2024-04-14T05:27:07.264525Z","shell.execute_reply":"2024-04-14T05:27:07.263436Z","shell.execute_reply.started":"2024-04-14T05:27:07.257100Z"},"trusted":true},"outputs":[],"source":["class CNNDetector(nn.Module):\n","\n","    def __init__(self, config={}):\n","\n","        super(CNNDetector, self).__init__()\n","\n","        self.backbone_1d = None\n","\n","        self.backbone_2d = efficientnet_b0(weights=\"IMAGENET1K_V1\")\n","        \n","#         self.backbone_2d.conv1 = nn.Conv2d(config.get(\"in_channels\",1), 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False)\n","        \n","        self.backbone_2d.classifier[1] = nn.Linear(1280, config.get(\"num_classes\", 6))\n","        \n","#         print(self.backbone_2d)\n","\n","        self.head = None\n","\n","    def get_loss(self, pred_dict):\n","\n","        pass\n","\n","    def forward(self, data_dict):\n","\n","        \"\"\"\n","        returns a dictionary pred_dict with the logits for loss calculation and gradient descent.\n","        \"\"\"\n","        \n","#         print(torch.isnan(torch.sum(data_dict[\"spec\"])))\n","\n","        return self.backbone_2d(data_dict[\"spec\"])"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:37:21.120108Z","iopub.status.busy":"2024-04-14T05:37:21.119749Z","iopub.status.idle":"2024-04-14T05:37:21.432607Z","shell.execute_reply":"2024-04-14T05:37:21.431524Z","shell.execute_reply.started":"2024-04-14T05:37:21.120078Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[torch.Size([10000, 19]), torch.Size([300, 400]), torch.Size([6])]\n","(tensor([[-1.2819,  0.2882,  0.4570,  ..., -0.2834,  0.6457,  2.7548],\n","        [-1.5526, -0.0509,  0.1064,  ..., -0.6653,  0.2747,  2.0454],\n","        [-1.3783,  0.2230,  0.4551,  ..., -0.3216,  0.5962,  2.5634],\n","        ...,\n","        [-0.9190,  0.3922,  0.1394,  ..., -0.7086,  0.2932,  0.5750],\n","        [-1.1416,  0.0568, -0.1324,  ..., -1.0253, -0.0764,  0.1086],\n","        [-1.1642,  0.0845, -0.0956,  ..., -0.9687, -0.0374,  0.1497]]), tensor([[ 2.9605,  2.9787,  2.9050,  ..., -0.7696, -0.7696, -0.7696],\n","        [ 2.6904,  2.7197,  2.5592,  ..., -0.8220, -0.8220, -0.8220],\n","        [ 0.7780,  0.6284,  0.5371,  ..., -0.3574, -0.5286, -0.7696],\n","        ...,\n","        [ 3.1196,  3.1458,  2.9791,  ..., -0.7696, -0.7696, -0.7696],\n","        [ 0.8603,  0.9655,  0.8206,  ..., -0.8220, -0.8220, -0.8220],\n","        [ 0.5371,  0.5030,  0.5030,  ..., -0.8220, -0.8220, -0.8220]]), tensor([0., 0., 0., 0., 0., 1.]))\n"]}],"source":["dataset = HMSDataset(df=train_df)\n","batch_size = 32\n","\n","print([data.shape for data in dataset[0]])\n","\n","print(dataset[0])"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T02:39:35.310349Z","iopub.status.busy":"2024-04-14T02:39:35.309988Z","iopub.status.idle":"2024-04-14T02:39:35.324053Z","shell.execute_reply":"2024-04-14T02:39:35.322936Z","shell.execute_reply.started":"2024-04-14T02:39:35.310321Z"},"trusted":true},"outputs":[],"source":["#testing\n","\n","@torch.no_grad()\n","def validate(model, valid_dataloader):\n","\n","    model.eval()\n","\n","    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n","\n","    loss = torch.tensor([0.]).to(device)\n","\n","    for batch in tqdm(valid_dataloader):\n","\n","        for key in batch:\n","\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","        \n","        predictions = F.log_softmax(predictions,dim=1)\n","\n","        loss += loss_fn(predictions,batch[\"label\"])\n","\n","    loss = loss / len(valid_dataloader)\n","\n","    model.train()\n","\n","    print(\"Validation loss\", loss.item())\n","\n","    return loss.item()\n","\n","def test(model, test_dataloader):\n","\n","    model.eval()\n","\n","    correct = 0\n","\n","    for batch in test_dataloader:\n","\n","        for key in batch:\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","\n","        predictions = F.softmax(predictions, dim=1)\n","\n","        predictions = torch.argmax(predictions,dim=1)\n","\n","        classes = torch.argmax(batch[\"label\"], dim=1)\n","\n","        correct += torch.sum(predictions == classes, dtype=torch.int)\n","\n","    model.train()\n","\n","#training\n","\n","def train_epoch(model=None,\n","          train_dataloader=None,\n","          valid_dataloader=None,\n","          optimiser = None,\n","          train_config=None,\n","          valid_config=None,\n","          lr_scheduler=None,\n","          min_valid_loss=100.,\n","          model_name=\"model\",\n","          epoch=0,\n","          logger=None):\n","    \n","    \"\"\"\n","    Training Function\n","    \"\"\"\n","\n","    assert(train_dataloader is not None)\n","    \n","    assert(model is not None)\n","\n","    #Training Params\n","\n","    save_model = train_config.get(\"save_model\", True)\n","    to_model_keys = [\"spec\", \"eeg\", \"label\"]\n","    valid_step = valid_config.get(\"valid_step\", 1000)\n","    verbose_step = train_config.get(\"verbose_step\", 10)\n","    \n","    \n","    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n","    \n","    model.train()\n","    \n","    for itr, batch in tqdm(enumerate(train_dataloader)):\n","\n","#       print(batch[\"eeg\"].shape)\n","\n","        #Train One Iteration\n","\n","        #Load data to GPU\n","\n","        for key in to_model_keys:\n","\n","            batch[key] = batch[key].to(device)\n","\n","        predictions = model(batch)\n","        \n","        predictions = F.log_softmax(predictions,dim=1)\n","\n","        loss = loss_fn(predictions,batch[\"label\"])\n","        \n","        optimiser.zero_grad()\n","\n","        loss.backward()\n","\n","        optimiser.step()\n","        \n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","        \n","        if itr%verbose_step==0:\n","            print(f\"Training itr {itr}/{len(train_dataloader)}\")\n","            for param_group in optimiser.param_groups:\n","                lr = param_group['lr']\n","                break\n","            print(\"Training Loss: \", loss, \"Learning Rate:\", lr)\n","\n","            logger.log_metric({\"KLDiv loss\":loss})\n","        \n","        #Test\n","        \n","        if itr%valid_step==0 and itr>0 and valid_dataloader is not None:\n","            print(\"Validation\")\n","            valid_loss = validate(model, valid_dataloader)\n","            \n","            if valid_loss < min_valid_loss and save_model:\n","                min_valid_loss = valid_loss\n","                save_path = os.path.join(DATA_ROOT,\"models\")\n","                os.makedirs(save_path, exist_ok=True)\n","                torch.save(model.state_dict(), os.path.join(save_path, f\"{model_name}_best.pt\"))\n","            logger.log_metric({\"Valid loss\":valid_loss})\n","    return min_valid_loss"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[],"source":["def train(model=None,\n","          optimiser=None,\n","          lr_scheduler=None,\n","          train_config=None,\n","          valid_config=None,\n","          model_name=\"model\",\n","          logger=None):\n","    \n","    train_batch_size = train_config.get(\"batch_size\", 32)\n","    num_epochs = train_config.get(\"num_epochs\", 10)\n","    valid_folds = train_config.get(\"valid_folds\", 5)\n","    valid_batch_size = valid_config.get(\"batch_size\", 32)\n","    train_workers = train_config.get(\"workers\", 1)\n","    valid_workers = valid_config.get(\"workers\", 1)\n","\n","    min_valid_loss = 100\n","\n","    for epoch in range(num_epochs):\n","\n","        print(\"Epoch\", epoch)\n","\n","        #KGFolds\n","        fold = np.random.randint(valid_folds)\n","        train_df_fold = train_df[train_df[\"fold\"]!=fold]\n","        valid_df = train_df[train_df[\"fold\"]==fold]\n","        train_dataset = HMSDataset(train_df_fold, aug=True)\n","        valid_dataset = HMSDataset(valid_df, aug=True)\n","\n","        train_dataloader = DataLoader(\n","            dataset=train_dataset,\n","            batch_size = train_batch_size,\n","            shuffle=False,\n","            num_workers=train_workers,\n","            collate_fn=train_dataset.collate_fn\n","        )\n","\n","        valid_dataloader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size = valid_batch_size,\n","            shuffle=False,\n","            num_workers=valid_workers,\n","            collate_fn=valid_dataset.collate_fn\n","        )\n","\n","        min_valid_loss = train_epoch(model=model,\n","                    train_dataloader=train_dataloader,\n","                    valid_dataloader=valid_dataloader,\n","                    optimiser=optimiser,\n","                    train_config=train_config,\n","                    valid_config=valid_config,\n","                    lr_scheduler=lr_scheduler,\n","                    min_valid_loss=min_valid_loss,\n","                    model_name=model_name,\n","                    epoch=epoch,\n","                    logger=logger)\n","        print(\"Min Valid Loss\", min_valid_loss)"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T02:39:35.801324Z","iopub.status.busy":"2024-04-14T02:39:35.800510Z","iopub.status.idle":"2024-04-14T02:56:53.096301Z","shell.execute_reply":"2024-04-14T02:56:53.094732Z","shell.execute_reply.started":"2024-04-14T02:39:35.801292Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","Epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'zero_grad'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-98-e79889042aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0mvalid_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       logger=logger)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-96-a48f49e9225f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimiser, lr_scheduler, train_config, valid_config, model_name, logger)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                     logger=logger)\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Min Valid Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_valid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-95-4be9ab1b30de>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_dataloader, valid_dataloader, optimiser, train_config, valid_config, lr_scheduler, min_valid_loss, model_name, epoch, logger)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'zero_grad'"]}],"source":["model_config = {}\n","\n","model = CNNDetector(model_config).to(device)\n","\n","train_config = {\n","    \"batch_size\": 32,\n","    \"num_epochs\": 1,\n","    \"lr\": 1e-3,\n","    \"valid_folds\":5,\n","    \"save_model\": True,\n","    \"workers\": 1,\n","    \"verbose_step\": 100,\n","    \"weight_decay\": 0.,\n","    \"valid_folds\": 5,\n","}\n","\n","valid_config = {\n","    \"batch_size\": 16,\n","    \"workers\": 1,\n","    \"valid_step\": 500\n","}\n","\n","lr = train_config.get(\"lr\", 1e-3)\n","weight_decay = train_config.get(\"weight_decay\", 0.)\n","model_name = \"efficientnetb0\"\n","num_epochs = train_config.get(\"num_epochs\", 1)\n","folds = train_config.get(\"valid_folds\", 5)\n","train_batch_size = train_config.get(\"batch_size\", 32)\n","\n","\n","logger = TensorBoardLogger(\"logs\", name=model_name)\n","\n","print(num_epochs)\n","\n","optimiser = torch.optim.Adam(\n","model.parameters(),\n","lr=lr,\n","weight_decay=weight_decay\n",")\n","\n","lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","    optimiser,\n","    max_lr=lr,\n","    epochs=num_epochs,\n","    steps_per_epoch=int((folds-1)/folds*train_df.shape[0]//train_batch_size)\n",")\n","\n","torch.cuda.empty_cache()\n","\n","train(model=model,\n","      train_config=train_config,\n","      valid_config=valid_config,\n","      model_name=model_name,\n","      optimiser=optimiser,\n","      lr_scheduler=lr_scheduler,\n","      logger=logger)\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":4}
